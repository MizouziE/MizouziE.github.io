[{"content":"I\u0026rsquo;m a back-end leaning full stack developer, so after a whole day of combing through and fixing someone else\u0026rsquo;s JavaScript code all day at work, there was no better way to blow off some steam while I sat waiting for my kid to finish his Taekwondo lesson than to read through and re-write my latest addition to this site.\nAdding copy to clipboard functionality to code blocks The latest addition I refer to was adding little \u0026ldquo;copy to clipboard\u0026rdquo; buttons in the corners of my example code blocks throughout this site. I always find them helpful when they\u0026rsquo;re available on documentation or tutorial sites, so I\u0026rsquo;d spent a couple of hours last night adding the necessary stylesheets for pretty code blocks and then going through the Hugo forums seeing how others had tackled this. I was grateful to stumble across a discussion in which someone had kindly provided a whole example repo/branch so I pulled it down and cherry-picked the parts that made it all tick, created a package.json file and ran npm ci. Boom! We had a cool little copy icon in the corner of every code block.\nExcitedly I pushed all my changes, which triggered the deployment workflows, and a minute later it was live and I was going through all my old articles marvelling at the copy-pasta-ness of it all. But\u0026hellip; the pages felt that tiny bit slower to load. They had lost that snap that had been the whole reason I was so enamored with Hugo built static sites in the first place. So before going to bed, I had a closer look at the actual contents of the package.json and was reminded of why the JavaScript ecosystem gets so much stick all the time. No less than four libraries were \u0026ldquo;required\u0026rdquo; to render these tiny icons and copy stuff to the user\u0026rsquo;s clipboard. That\u0026rsquo;s bonkers. So I did some [over]due diligence and learned about the Clipboard API which had full support in most browsers since ages ago. Why wasn\u0026rsquo;t I just using that?\nLet\u0026rsquo;s just use that!\nUsing Clipboard.js in a Hugo site I would certainly not have been able to write this all from scratch, even with a solid understanding of the API, but I didn\u0026rsquo;t have to. I already had what was shown here as a starting point, so it was simple to break down the steps of what needed to be done. We\u0026rsquo;ll break down the function that does the heavy lifting addCopyToClipboardButtons(containerClass, buttonClass = 'copy-button') here:\nCreate and add the button to each of the code block \u0026lsquo;containers\u0026rsquo; const containers = document.querySelectorAll(`.${containerClass}`); containers.forEach(container =\u0026gt; { const button = document.createElement(\u0026#39;button\u0026#39;); button.className = buttonClass; button.innerHTML = icons.faCopyRegular; container.prepend(button); }); Create the clipboard object, the most of which is handled by the main dependency const clipboard = new ClipboardJS(`.${buttonClass}`, { target: function(trigger) { return trigger.nextElementSibling; } }); Handle a successful copy operation clipboard.on(\u0026#39;success\u0026#39;, (e) =\u0026gt; { if (e.action === \u0026#39;copy\u0026#39;) { const originalIcon = e.trigger.innerHTML; e.trigger.innerHTML = icons.faCheck; setTimeout(() =\u0026gt; { e.trigger.innerHTML = originalIcon; e.clearSelection(); }, iconChangeTimeout); } }); Handle an error during a copy operation clipboard.on(\u0026#39;error\u0026#39;, (e) =\u0026gt; { console.error(\u0026#39;ClipboardJS Error:\u0026#39;, e.action, e.trigger); const originalIcon = e.trigger.innerHTML; e.trigger.innerHTML = icons.faBomb; // Assuming you have a cross or \u0026#39;times\u0026#39; icon setTimeout(() =\u0026gt; { e.trigger.innerHTML = originalIcon; }, iconChangeTimeout); }); It\u0026rsquo;s actually quite elegant as it is, the only gripe I really had with it is that it requires loading a whole bunch of stuff that likely unused. So based on this, we can quite easily swap out the parts that matter.\nCopy to clipboard buttons in Hugo with vanilla JavaScript Step 1 of the above breakdown is actually perfect as it is. There is nothing other than native JS and we end up with some useful bits we can come back to later.\nStep 2 is where we can start to swap out the library for the native API. I had them side by side as I was working out the bugs so we\u0026rsquo;ll give it a \u0026ldquo;new\u0026rdquo; name for now\nconst newClipboard = window.navigator.clipboard Next, our main difference between the ClipboardJS implementation and the native API is that the former is very similar to jquery and offers an on() method to deal with either a success or failed operation, while the latter is more aligned with the fetch() API which has then() and catch() methods for dealing with the successfully resolved promise or the failure to do so. This means, that unlike our steps 3 and 4 above being totally separated, we can write a more \u0026ldquo;try/catch\u0026rdquo; (hooray for PHP) style chain of instructions.\ncontainers.forEach(container =\u0026gt; { const button = container.querySelector(`.${buttonClass}`); button.addEventListener(\u0026#39;click\u0026#39;, function () { const text = this.nextElementSibling.textContent; newClipboard.writeText(text) .then(() =\u0026gt; { const originalIcon = this.innerHTML; this.innerHTML = icons.faCheck; setTimeout(() =\u0026gt; { this.innerHTML = originalIcon; }, iconChangeTimeout); }) .catch((e) =\u0026gt; { console.error(\u0026#39;Error copying to clipboard:\u0026#39;, e.action, e.trigger); const originalIcon = this.innerHTML; this.innerHTML = icons.faBomb; setTimeout(() =\u0026gt; { this.innerHTML = originalIcon; }, iconChangeTimeout); }); }); }); This actually reads quite nicely already for describing what it is doing:\nGrab our containers For each of them; Find the button Add a click event listener in which we; Capture the next element sibling\u0026rsquo;s text content (Our demonstration code) Write that text to the operating system\u0026rsquo;s clipboard Then do nice things like show the user something has happened by swapping the icon to a check mark If there was an error, show a bomb icon instead and write the error to the console After a set amount of time, swap the icon back to the clipboard icon Now that it\u0026rsquo;s converted, we can see how simple this action really is. That means that there is room for improvement! Did you notice how we\u0026rsquo;ve got a couple of places where we\u0026rsquo;re repeating actions or redeclaring the same thing? By moving one of the const declarations up a scope level, it becomes accessible everywhere it is required, and we also seem to be doing two nested forEach loops of the same things. In the end I thought this was a nice enough level of squished to retain it\u0026rsquo;s readability and still work just as we want it to.\nimport * as icons from \u0026#39;./icons.js\u0026#39; function addCopyToClipboardButtons() { const iconChangeTimeout = 1300; const containers = document.querySelectorAll(\u0026#39;.highlight\u0026#39;); containers.forEach(container =\u0026gt; { const button = document.createElement(\u0026#39;button\u0026#39;); button.className = \u0026#39;copy-button\u0026#39;; button.innerHTML = icons.faCopyRegular; container.prepend(button); button.addEventListener(\u0026#39;click\u0026#39;, function () { const originalIcon = this.innerHTML; const text = this.nextElementSibling.textContent; window.navigator.clipboard.writeText(text) .then(() =\u0026gt; { this.innerHTML = icons.faCheck; setTimeout(() =\u0026gt; { this.innerHTML = originalIcon; }, iconChangeTimeout); }) .catch((e) =\u0026gt; { console.error(\u0026#39;Error copying to clipboard:\u0026#39;, e.action, e.trigger); this.innerHTML = icons.faBomb; setTimeout(() =\u0026gt; { this.innerHTML = originalIcon; }, iconChangeTimeout); }); }); }); } export { addCopyToClipboardButtons } It\u0026rsquo;s very likely that there are further optimisations that could be made. The setTimeout()s could probably go on one line, for instance, but as I said, I was waiting for a Taekwondo lesson to finish, and at this point, it did, so that\u0026rsquo;s as far as I went.\nOnce I got home I went and did my favourite thing to do and went through my files and hit delete on package.json, package-lock.json and all of node_modules and even got to go back into my .github/workflows/*.yaml files and remove the entire JS build step \u0026#x1f389;. And then I took the great feeling that gave me and came straight into a new markdown file and started writing out this here post.\nSeeing how simple yet powerful modern JavaScript can be does make me appreciate this strange little language at times. And when it is put together with something as fast and elegant as a nice static website? Forget about it. So Go Hugo some sites and see what else can be wrangled!\n","date":"2025-12-09","id":"ac110ee1fa5ae7dee4dd6a57ecfcbd26","permalink":"https://www.mizouzie.dev/articles/code-block-click-copy/","summary":"How to swap a Clipboard.js dependency for vanilla JavaScript","tags":["web dev","open source","learning","hugo","javascript","no build"],"title":"Code Block Click Copy"},{"content":" tūm (pronounced /tuːm/) — “then,” “at that moment”; here, a glance back at what once was and the moments that shaped the beginning.\nmŏdō (pronounced /ˈmɔ.doː/) — “just now,” “only now”; a grounding in the present, the point of clarity from which everything is assessed.\npostĕā (pronounced /ˈpɔs.tɛ.aː/) — “afterward,” “later on”; a forward-looking view toward what may unfold from this moment onward.\nGiven that I\u0026rsquo;ve re-kindled my interest in this little blog of mine, and that it\u0026rsquo;s almost Christmas, it seems a fitting time to get a bit Charles Dickens and have a look at my past, present and future. Part of the reason I have picked this thing back up is that I finally feel settled in the job I\u0026rsquo;ve been at for a few years and actually have a bit of time now because I\u0026rsquo;m not constantly trying to catch up with everyone. Not that having been in a catch up loop was a bad thing, it was nothing short of a huge opportunity to learn a tonne and really add some serious strings to my web developer bow. I think it\u0026rsquo;s going to be a very worthwhile exercise to look back at where I was when I started out, honestly assess where I\u0026rsquo;m at currently and then see what avenues I think Id like to go down in the not too distant future.\nThen Back in November 2023, I took my first flight back to the UK for work to attend my initial training for a job at Fusions PIM ltd. I had already been working in web development and with Laravel for a couple of years, so wasn\u0026rsquo;t totally green. My CV at the time listed core skills like:\nLaravel (2 years experience) Built customer requested features into an existing project Built a CRM and knowledge base for a subscription based retail company from scratch Docker Comfortable working in development containers Hosting dockerised web applications on bare servers Using containers to \u0026ldquo;try out\u0026rdquo; different elements of tech stacks Open Source Started and managed a small web crawler project aimed at offering beginners an opportunity to try out OSS In fairness, I\u0026rsquo;d not made a bad start considering my first experience with any of this world was when I did my first Laracasts tutorial in 2021. But my actual real world experience, and impact on the actual industry would not have even registered as negligible. Looking back I\u0026rsquo;m a little astonished that this long established company took a punt on me, but I\u0026rsquo;m very glad they did.\nWhat I lacked in experience I tried my best to make up for with soft skills like clear communication, not being afraid to look a bit daft by asking a silly question and apart from that just trying really hard to up my levels constantly. I\u0026rsquo;d been lucky before where I had worked in that I had a huge amount of freedom to manage myself and my workload, and that did not change when I arrived here, even though the company technically had to be more \u0026ldquo;organised\u0026rdquo; to allow for customer transparency and coordination. So I\u0026rsquo;d work on what I needed to work on, I could literally ask any one of my new colleagues for advice or help as and when I needed it and I still had time to just read and read and read. The reason this reading experience was so valuable was that the codebase I as now working in had been around since long before I\u0026rsquo;d learned even a single function of PHP. Some of the classes had syntax from years ago. A true legacy monster. Even though a great deal of it had been already converted into a Laravel app, there were still plenty of old quirks that were too fundamental to the business to risk chopping and changing them, so they were just as they were. It was kind of like being locked in a time-rift, but that had more benefits than I realised at the time.\nSome context of the conversion in progress;\nThe application had already had a very similar structure to that of a Laravel app from the start Many of the Symfony components that Laravel is built on top of were already being used The parts that differed most in the application were to do with more old fashioned security concerns Now Skip ahead a few years and that same mysterious and enormous PHP application that was half-of-yesteryear has been converted almost 100% to a modern Laravel app, through the efforts of colleagues old and new and of myself. The main takeaway I had from being a part of this conversion was that I had to gain a deeper understanding of the Laravel framework because the parts that were left to convert were the more challenging ones, which makes sense as they\u0026rsquo;d have been bonkers to have not started the conversion before I got there with anything other than the easier parts. I think the areas I got my teeth into the most were Eloquent and Commands, but I definitely was routing around in almost all areas of the framework codebase.\nEloquent A lot of the older parts of the codebase I was working on used proper old school PHP syntax of $sql = 'SELECT * FROM `some_table` WHERE `x` = 'y'; so I got lots of practice reading and understanding SQL, the re-writing to get the same results using eloquent queries. Not only that, much of the application was to do with search filtering based on model relationships so I had to make sure I really understood how relations could be properly defined and used for querying. Over the years I was doing this, eloquent methods for querying relationships were improving week on week and I was constantly being presented with ways to improve what we had, both for performance and for developer experience.\nThe main thing I love about eloquent is how well it reads, especially around relations. A lot of the time there\u0026rsquo;s no need to think too hard about what is happening because the methods, like withWhereHas('relation', fn ($query) =\u0026gt; $query-\u0026gt;condition()), tell you exactly what the result is going to contain.\nCommands My appreciation for Symfony knows no bounds because I\u0026rsquo;ve really been in the trenches of the docs for just the console and it\u0026rsquo;s pretty awesome when you consider how fundamentally simple it\u0026rsquo;s been kept. In my humble opinion, Laravel has obscured some of the simplicity in the parts they\u0026rsquo;ve borrowed, for instance when you combine the testing helpers $this-\u0026gt;artisan(Command::class)-\u0026gt;expectsTable([...]), which makes a huge assumption that you\u0026rsquo;ve defined the table styling, with a command output table in which you\u0026rsquo;ve not defined the style for you\u0026rsquo;ll be momentarily stumped why your tests are failing before figuring out that the default style for tables in Laravel is not the same as the default style for tables in Symfony \u0026#x1fae4;\nApart from the small quirks, the capabilities of commands is fantastic and it even inspired some thoughts in me that lead me into the speculative part of this assessment that will be explored a little later.\nOverall Having spent this time writing code, as well as reading and reviewing a lot of code of high quality, my style and even thought process when solving problems has improved a great deal. I am happy with where I\u0026rsquo;m at currently, but can certainly see the edges of my own scope for improvement and will continue to chase after it. I\u0026rsquo;ve kept up with practicing outside of work with things like CodeWars and tried to maintain my interest in languages outside of my 9 to 5 use of PHP and SQL, mostly bash and Golang but also recently delving into C++. Also, because I\u0026rsquo;ve recently reached this comfort level I\u0026rsquo;ve picked up this small side project and hope to be able to maintain writing again, as it definitely did contribute to me developing my own understanding back when I started out.\nContributing to open source projects has become a more regular thing recently, which has boosted my confidence somewhat as well as been a great opportunity to see how different, well established projects work and some experiences resulted in positive changes in my day to day work.\nHaving reached this level has afforded me more time to pursue other old hobbies like reading too, which has been great for me personally and has inspired a new dimension of this very personal website that I\u0026rsquo;m quite excited to get launched soon (Look out for a tl;dr section up in the navigation!).\nAfter So seeing as I think that I managed to reach the \u0026ldquo;next level\u0026rdquo; that I\u0026rsquo;d envisaged when starting out at my current position, what comes next?\nI have had experience of working under some great development managers, and I think that I should (and will) aim for not their position, but their mentality. I believe the next major improvement that I can make is being able to think X steps ahead and in a big picture sense, regardless of how cliché that sounds. I mean, things become cliché when they\u0026rsquo;re tried and true, no?\nWhat I mean is that I hope to improve my decision making when facing a problem, or writing a feature. I have gained a decent amount of experience and should be able to leverage that into foresight, while still building and reinforcing that experience. I have seen first hand how all decisions (in a architectural sense) are about trade-offs as there\u0026rsquo;s never a truly 100% correct solution, just a best-fit one, or even two. I want to be able to weigh up the pros and cons with confidence and then execute plans based on those decisions. I even have a few examples of this type already in my sights, so I want to be sure that I am pursuing them with a level head and not for the sake of wanting to \u0026ldquo;establish\u0026rdquo; myself or anything selfish like that.\nAnother thing I hope to develop in myself is to keep focused on what matters in a business sense. I\u0026rsquo;ve been guilty of spending too much time writing things \u0026ldquo;the right way\u0026rdquo; when the actual business value of the thing I\u0026rsquo;m writing is small. At the end of the day, we build tools to solve business problems. When we solve the problem, we gain value, and making the code clever, or pretty doesn\u0026rsquo;t actually make as huge of a difference as we feel like we\u0026rsquo;re making while doing it. A great video explaining this from 2025 Laracon EU by John Drexler, which my team and I were actually in attendance for, sums it up perfectly and even though my teammates and I constantly refer back to it, I know for a fact that I can still implement the mentality much better than I do now. By doing this more strictly I will greatly improve my value as a developer.\nSo after that brief look backward, inwards and forwards, I think I am mostly grateful for the opportunities I have been presented and I am actually pleased with what I have managed to achieve with them, which definitely does not align with how I felt back then \u0026#x1f605;\nI could probably be a little easier on myself, because having struggled with things did not mean I was as dumb as I felt!\n","date":"2025-12-01","id":"ebb9817c17bf17f7aabf69442e8213e7","permalink":"https://www.mizouzie.dev/articles/then-now-after/","summary":"A retrospective look at what I came from, assessment of where I currently am, and a prospective look at where I see myself going","tags":["web dev","learning","mental health","self-care"],"title":"Tum | Modo | Postea"},{"content":"\nHow I thought it would go I had always seen people working on their laptops in airports and on aeroplanes, so it was an easy assumption to make that I too would be able to do so. I have two projects on-going and definite next steps that need to be done for each. Fairly monotonous tasks that I should be comfortable with and can just get on with.\nNormally, when working at home I only get about 2.5 hours in the day when I am 100% left alone and can focus fully on a task. This golden hour is great, but I\u0026rsquo;d love to know how productive I could be given the opportunity of a longer window of focus. Stuck in a seat on a plane, without having to entertain my 6 year old son for at least 3 hours with the potential of an additional hour either end of waiting around. Sounds like a great chance to find out!\nI usually work on remote development servers so that was something to consider. There\u0026rsquo;s no WiFi at 30,000ft in economy class. But, as I said, my tasks were not anything new to me, so as long as I had my repository saved locally I should probably be ok. I\u0026rsquo;ve written hundreds of tests in the last few months alone, and I need to write some for a fresh project so they\u0026rsquo;ll be super basic. Should be a blast. Alternatively I\u0026rsquo;ve got some HTML to steal from a template email and incorporate into some usable components for another project. Low level stuff.\nPreparations So my main concern was that most of my current work is remote, so first thing to do was to git clone everything I intended to work on into a local directory. Simple enough.\nThe projects are Laravel applications, so I made sure to set up my .env and run composer install \u0026amp;\u0026amp; npm install so that all my dependencies were available. Luckily I had an inkling to be extra cautious and tried to run my migrations to make sure the MySQL database was all ok. I say luckily because I didn\u0026rsquo;t actually have MySQL or MariaDB installed!\nSo I went about installing MariaDB as I had always just used docker for my databases when working locally before moving over to a remote development server. For some reason I have gone off of Docker lately so prefer to just run MariaDB (the OSS and friendly version of MySQL) on my machine. I did write about running databases in Docker before which you can read by clicking here.\nI made sure to have my laptop battery, phone battery and headphones battery all fully charged and even made sure to have some good old fashioned mp3s saved on my phone so I could still listen to music without streaming.\nFor the project that I need to convert some HTML to components, I made sure to save a copy of the HTML from the page where you can preview the email. Even went s far as to check that I could see it lal properly when serving just my single stolen page. And it worked just right immediately.\nHow it really went Safe to say nothing went like I imagined\u0026hellip;\nProject #1 This is a work project, fresh Laravel app that I spent the previous few days designing and laying out the models and database structure for. I had to start some basic tests as I\u0026rsquo;d kept everything fairly loose while figuring out what kind of relationships the models all needed between them. Now that I was more settled, it was time to write the tests to ensure that further changes don\u0026rsquo;t break things.\nSo I write my first test, easy enough. Goes green after not too many errors. Second test the same. Then I want to refactor early to avoid repeating myself in populating the database with data and an authenticated user. I\u0026rsquo;d done this before I\u0026rsquo;m sure, what I believe I need is:\npublic function __construct( public User $user, public Client $clients, ) {} public function setup(): void { $this-\u0026gt;user = User::factory()-\u0026gt;create(); $this-\u0026gt;clients = Client::factory(50)-\u0026gt;create(); } But it turned out that this isn\u0026rsquo;t what I needed. I am somehow passing a string to the typed variable\u0026hellip; as I sit here now, still on the plane I cannot put my finger on how I am doing this wrong, but I know that if I had an internet connection right now all I need to is check a repo I worked on a week or two ago (on the remote server) and I\u0026rsquo;ll see immediately how I wrote the actual needed thing rather than this terrible recollection/representation of it.\nI know it\u0026rsquo;s possible to run a setup() method to run what ever seeding you want or create a user that will be reusable between tests. I know because I did it recently. It\u0026rsquo;s very frustrating that I can\u0026rsquo;t recall it right now.\nEdit, the following day: I found what my problem was in the docs. I should have used setUp() with an uppercase \u0026ldquo;U\u0026rdquo; and also called parent::setUp() within my method. I found it at the bottom of this section about testing. What I actually needed was the following:\nprivate User $user; private Collection $clients; public function setUp(): void { parent::setUp(); $this-\u0026gt;user = User::factory()-\u0026gt;create(); $this-\u0026gt;clients = Client::factory(50)-\u0026gt;create(); } I could just repeat myself for the moment and come back to refactor later having referred to the docs or even my older code. So let me write some tests using the $this-\u0026gt;actingAs($user) to make sure I wasn\u0026rsquo;t getting redirected to a login route. Oh, there is no login route. I had only installed Breeze, Laravel\u0026rsquo;s quick and easy solution to out-of-the-box auth, on a branch that got scrapped after a front end re-design. Great\u0026hellip; No matter, even though I cannot quickly download and install Breeze again without internet, I can just git cherry-pick the commit from the abandoned branch on which I had previous installed it. As it is mostly new files and my current routes/web.php file is untouched, then the changes brought shouldn\u0026rsquo;t break anything.\nI impressed myself that I managed to do this without Googling anything, if I\u0026rsquo;m honest. It worked. The thing I did not anticipate was all the changes to tailwind that would require another npm install\u0026hellip; damn it. My front end was now broken and I could not run npm run dev without it crashing. I had a hacky way of circumventing this that involved commenting out some lines in the postcss.config.js file but it was ugly, and I even tried just abandoning the middleware('auth') on the routes altogether to just write some tests but I was pissing in the wind at this point. Move on Sam.\nNever mind, I have a backup for this situation.\nProject #2 This is a project I\u0026rsquo;m working on for a friend that is a partly automated email sending app. I have already written all the guts of it and it sends what we want and collects email addresses etc and that\u0026rsquo;s all great. Now it just needs the front end polish, which I typically hate, but He made a template using MailChimp email builder and all I had to do was sift through it and pick out the various parts and styling that we wanted in our email.\nI had glanced at the HTML when I copied it and it looked ok-ish. But on closer inspection it was a straight up mess. Toxic even. Style attributes in almost all HTML tags. The whole thing was one big table with forced layout sizes. Not only that, the entire \u0026lt;body\u0026gt;...\u0026lt;/body\u0026gt; was written on a single line and even with my autoformatter, I could not get it into a sensible layout, so picking out bits and editing others was a horrendous amount of side scrolling.\nOh and did I mention that the kid sitting in the seat in front of me was some kind of jack-in-the-box? Every time he jumped, my thumb would accidentally swipe over the tracking pad and loose the place I had just painstakingly scrolled to. I tried working with the laptop on my actual lap, as the name may suggest is easy to do so, but it\u0026rsquo;s a poxy little 14\u0026quot; screen so it was very uncomfortable. Did not help that the style of plane seat arrangement was inline with a tin of sardines. No legroom whatsoever .\nLessons learned So absolutely nothing that I planned to get done got done. Zero for two. Instead of letting myself get mad about it, I decided to write this so that I could at least gain something from this experience. The main lessons I learned were:\nDeveloping a Laravel 10 application without an internet connection is tough if you\u0026rsquo;ve not got all your packages inline beforehand. Even doing tasks that had been done repeatedly before can sometimes need the littlest bit of help from some reference, be it documentation or an old project. Before doing things totally offline, doing a dry-run is probably a good idea to catch the trivial hurdles. HTML generated from \u0026ldquo;builder\u0026rdquo; style tools can be clunky and follow anti-patterns. I am better at git than I used to be. (Maybe because I messed it up so many times!) Cheap flights do not have a comfortable amount of room to think in. It\u0026rsquo;s better to write content than code in my case, because I am still too dependant on documentation. ","date":"2023-07-05","id":"9d02ce42b61138b155344bdf5549778a","permalink":"https://www.mizouzie.dev/articles/tried-working-at-30000ft/","summary":"The rare occasion of me traveling alone came up and I was excited to have a few hours alone with my thoughts and make the most of the opportunity to get loads of work done.","tags":["web dev","self-care"],"title":"I Tried Working at 30,000ft"},{"content":"\nIntroduction I had a task a few months back of discovering the cause of a bug in a production environment that just was not presenting itself in development, mostly due to the creators and users of the application having ever so slightly differing ideas about how the app should be used. This meant that in all of our testing while making the application, we never saw the bug that was being reported. The solution for this was to take a copy of the production database and use that in development to try and replicate the reported issue.\nThe application was a CMS (Content Management System) that had a few extra niceties that introduced a little more complex database structuring, so that could be one reason it was hard for the development team to preempt this problem. All the same, the tech lead went ahead and made a mysqldump file blogs.sql.gz and promptly forwarded it to me to get to work with figuring things out. All our development work is done on a dedicated development remote server, and I had the file on my local machine so I\u0026rsquo;d need to extract and upload the file to the remote server, which was something I had not previously done.\nI will cover the steps I went through in order to discover how exactly how to get the database created and populated with the desired data. It was a journey of discover for me as I was making use of tools that I was familiar with as well as new (to me) tools and therefore had some steps that may not be deemed necessary, but I will include them as they taught me something and my goal is to share those lessons.\nI had a few specific problems which I will explain in more detail further down, which caused a few of the extra steps I took so there is more to learn here than just uploading data. As well as just documenting my thought process for my own benefit, I hope to offer some guidance to other junior developers in ways to approach the type of problems that cost us a lot of time when we are starting out.\nTL;DR I went through steps that allowed me to read the dump file, attempted to pipe that to the remote server, read the error messages and made whatever changes I needed and repeated until I had what I needed and eventually uploaded the data so I could have an exact copy of production on my development environment.\nSkip down to Final working Command to see the command I ended up with.\nUse case In the case I am presenting here we have;\na zipped mysqldump file (.gz) located in ./Downloads/blogs.sql.gz the file contains a number of mysqldump: [Warning]/Error... lines (due to being made with/without a password) a remote server to which we have ssh access, denoted by \u0026lt;user\u0026gt;@\u0026lt;hostname\u0026gt; mysql installed on said server Particular problems we face The first stumbling block was the warnings that do not parse normally when uploading a mysqldump file. Their presence breaks the stream and so nothing after them will be read. I ended up solving this problem in more than one way as you will see by the end. My first \u0026ldquo;solution\u0026rdquo; introduced new problems that became apparent later on.\nOther uses There is no reason I see that the working knowledge highlighted in the rest of this article cannot be beneficial to other use cases where, for example, a mysql dump file devoid of any warnings needs to be uploaded. I will break down each part of any commands we examine, so you can decide which you need to apply for your case.\nSubjects we will cover A number of tools will be covered, so I will introduce them briefly here and explain their specific uses and additional flags when appropriate.\nCommand Description gzip compress or expand files tail output the last part of files head output the first part of files ssh OpenSSH remote login client mysql a simple SQL shell that supports interactive use sed stream editor for filtering and transforming text | (pipe) help combine two or more commands and are used as input/output concepts in a command. Steps You can see the whole raw interaction I had by clicking here and see the MySQL set up by clicking here.\n1. Create the database The first step is to use ssh to access the development server and be able to make changes using the mysql shell to add a new database that we will populate from the dump file.\nsam@Mizouzie:~$ ssh \u0026lt;user\u0026gt;@\u0026lt;hostname\u0026gt; -A This will get us in.\n\u0026lt;user\u0026gt;@\u0026lt;hostname\u0026gt;:$ mysql Welcome to the MariaDB monitor. Commands end with ; or \\g. Your MariaDB connection id is 15401 Server version: 10.6.12-MariaDB-1:10.6.12+maria~deb11 mariadb.org binary distribution Copyright (c) 2000, 2018, Oracle, MariaDB Corporation Ab and others. Type \u0026#39;help;\u0026#39; or \u0026#39;\\h\u0026#39; for help. Type \u0026#39;\\c\u0026#39; to clear the current input statement. Now on the development server, use the mysql command to open the shell client.\nMariaDB [(none)]\u0026gt; show databases; +-----------------------+ | Database | +-----------------------+ | information_schema | | content_generator | | example_laravel | | next_con_gen | +-----------------------+ 4 rows in set (0.001 sec) MariaDB [(none)]\u0026gt; create database example_laravel_dummy -\u0026gt; ; Query OK, 1 row affected (0.000 sec) MariaDB [(none)]\u0026gt; show databases; +--------------------------+ | Database | +--------------------------+ | information_schema | | content_generator | | example_laravel | | example_laravel_dummy | | next_con_gen | +--------------------------+ 5 rows in set (0.001 sec) Use show databases; to check existing databases In this case our development DB is example_laravel so we will create a dummy version example_laravel_dummy which we\u0026rsquo;ll use later. Use show databases; once more to confirm it was created.\n2. Try to import directly sam@MizouziE:~$ ssh \u0026lt;user\u0026gt;@\u0026lt;hostname\u0026gt; -A \u0026#34;mysql -u sam -p example_laravel_dummy\u0026#34; \u0026lt; ./Downloads/blogs.sql.gz Enter password: ERROR 1045 (28000): Access denied for user \u0026#39;sam\u0026#39;@\u0026#39;localhost\u0026#39; (using password: YES) Here we are using ssh and feeding a command into it by passing a string between quotation marks. Effectively we are running mysql -u sam -p example_laravel_dummy on the remote server but from our local machine.\nI should not have used the -p flag for a password, so let\u0026rsquo;s omit that.\nsam@MizouziE:~$ ssh \u0026lt;user\u0026gt;@\u0026lt;hostname\u0026gt; -A \u0026#34;mysql -u sam example_laravel_dummy\u0026#34; \u0026lt; ./Downloads/blogs.sql.gz ERROR: ASCII \u0026#39;\\0\u0026#39; appeared in the statement, but this is not allowed unless option --binary-mode is enabled and mysql is run in non-interactive mode. Set --binary-mode to 1 if ASCII \u0026#39;\\0\u0026#39; is expected. Query: Sd\u0026#39;. Now the file format is a problem as we have not extracted it.\nsam@MizouziE:~$ ssh \u0026lt;user\u0026gt;@\u0026lt;hostname\u0026gt; -A \u0026#34;mysql -u sam example_laravel_dummy\u0026#34; \u0026lt; gzip -dk ./Downloads/blogs.sql.gz bash: gzip: No such file or directory We need to install gzip, so go ahead and do that.\nsam@MizouziE:~$ gzip -cd ./Downloads/blogs.sql.gz | ssh \u0026lt;user\u0026gt;@\u0026lt;hostname\u0026gt; -A \u0026#34;mysql example_laravel_dummy\u0026#34; ERROR 1064 (42000) at line 1: You have an error in your SQL syntax; check the manual that corresponds to your MariaDB server version for the right syntax to use near \u0026#39;mysqldump: [Warning] Using a password on the command line interface can be in...\u0026#39; at line 1 The two flags used -c \u0026amp; -d with gzip will write the output on to standard output and decompress which is what allows us the then pipe that output into our following ssh command.\nAlso note that we have inverted the command to run gzip first so that we pipe the output of that into the ssh command.\nOur new error indicates a syntax error in the SQL statement we wish to run via the mysql command. That brings us to the next step.\n3. Read the mysqldump file In order to see why and where we have this issue, we can use the head command to read the first 10 lines of the file after unzipping it.\nsam@MizouziE:~$ gzip -cd ./Downloads/blogs.sql.gz | head mysqldump: [Warning] Using a password on the command line interface can be insecure. -- MySQL dump 10.13 Distrib 8.0.33, for Linux (aarch64) -- -- Host: localhost Database: blogs -- ------------------------------------------------------ -- Server version\t8.0.33 /*!40101 SET @OLD_CHARACTER_SET_CLIENT=@@CHARACTER_SET_CLIENT */; /*!40101 SET @OLD_CHARACTER_SET_RESULTS=@@CHARACTER_SET_RESULTS */; /*!40101 SET @OLD_COLLATION_CONNECTION=@@COLLATION_CONNECTION */; We can see by this output that the line beginning with mysqldump: [Warning] is problematic and not recognised as proper SQL syntax. Furthermore, the following lines are commented out so they could also be omitted.\n4. Skip first 7 lines So as our first 7 lines contain bad syntax and useless information, let\u0026rsquo;s send the same output but without the first 7 lines. Similar to head, we can use tail to send everything after a specified line number by making use of the -n flag with a positive (+) integer.\nsam@MizouziE:~$ gzip -cd ./Downloads/blogs.sql.gz | tail -n +7 | ssh \u0026lt;user\u0026gt;@\u0026lt;hostname\u0026gt; -A \u0026#34;mysql example_laravel_dummy\u0026#34; ERROR 1064 (42000) at line 12: You have an error in your SQL syntax; check the manual that corresponds to your MariaDB server version for the right syntax to use near \u0026#39;mysqldump: Error: \u0026#39;Access denied; you need (at least one of) the PROCESS priv...\u0026#39; at line 1 New error, but similar to the one we came across before. This means we must delve a little deeper down the file.\n5. Read further down the file We can use a -n flag on head to specify the number of lines shown. Without this flag it defaults to 10, so we will use a higher number to see more than before.\nsam@MizouziE:~$ gzip -cd ./Downloads/blogs.sql.gz | head -n 25 mysqldump: [Warning] Using a password on the command line interface can be insecure. -- MySQL dump 10.13 Distrib 8.0.33, for Linux (aarch64) -- -- Host: localhost Database: blogs -- ------------------------------------------------------ -- Server version\t8.0.33 /*!40101 SET @OLD_CHARACTER_SET_CLIENT=@@CHARACTER_SET_CLIENT */; /*!40101 SET @OLD_CHARACTER_SET_RESULTS=@@CHARACTER_SET_RESULTS */; /*!40101 SET @OLD_COLLATION_CONNECTION=@@COLLATION_CONNECTION */; /*!50503 SET NAMES UTF8 */; /*!40103 SET @OLD_TIME_ZONE=@@TIME_ZONE */; /*!40103 SET TIME_ZONE=\u0026#39;+00:00\u0026#39; */; /*!40014 SET @OLD_UNIQUE_CHECKS=@@UNIQUE_CHECKS, UNIQUE_CHECKS=0 */; /*!40014 SET @OLD_FOREIGN_KEY_CHECKS=@@FOREIGN_KEY_CHECKS, FOREIGN_KEY_CHECKS=0 */; /*!40101 SET @OLD_SQL_MODE=@@SQL_MODE, SQL_MODE=\u0026#39;NO_AUTO_VALUE_ON_ZERO\u0026#39; */; /*!40111 SET @OLD_SQL_NOTES=@@SQL_NOTES, SQL_NOTES=0 */; mysqldump: Error: \u0026#39;Access denied; you need (at least one of) the PROCESS privilege(s) for this operation\u0026#39; when trying to dump tablespaces -- -- Table structure for table `activity_log` -- DROP TABLE IF EXISTS `activity_log`; /*!40101 SET @saved_cs_client = @@character_set_client */; In this output we see that there is another error message that breaks syntax rules. This one follows after a number of settings that may be safe to assume are ok by default, so we will try to use tail like before but from ven further down the file.\nsam@MizouziE:~$ gzip -cd ./Downloads/blogs.sql.gz | tail -n +24 | ssh \u0026lt;user\u0026gt;@\u0026lt;hostname\u0026gt; -A \u0026#34;mysql example_laravel_dummy\u0026#34; ERROR 1005 (HY000) at line 96: Can\u0026#39;t create table `example_laravel_dummy`.`article_background_image` (errno: 150 \u0026#34;Foreign key constraint is incorrectly formed\u0026#34;) Now we see that this will not work because we omitted something important. Namely the line /*!40014 SET @OLD_FOREIGN_KEY_CHECKS=@@FOREIGN_KEY_CHECKS, FOREIGN_KEY_CHECKS=0 */;.\n6. Set important server variables We can try to set the missing server variable and keep our current way of feeding the SQL statement by using --init command=[command] after mysql. We will use that to disable the foreign key checks.\nsam@MizouziE:~$ gzip -cd ./Downloads/blogs.sql.gz | tail -n +24 | ssh \u0026lt;user\u0026gt;@\u0026lt;hostname\u0026gt; -A \u0026#34;mysql --init-command=\\\u0026#34;SET SESSION FOREIGN_KEY_CHECKS=0;\\\u0026#34; example_laravel_dummy\u0026#34; ERROR 1231 (42000) at line 2261: Variable \u0026#39;time_zone\u0026#39; can\u0026#39;t be set to the value of \u0026#39;NULL\u0026#39; Here we have yet a different error, but it\u0026rsquo;s cause is very similar to the last error we encountered. It is down to omitting those seemingly \u0026ldquo;safe to omit\u0026rdquo; server variables from the start of the mysqldump file. We need another approach.\n7. That\u0026rsquo;s what she sed sed now makes itself useful to us as we can use it with it\u0026rsquo;s regexp matching ability to remove certain lines from the file stream as they are being streamed. What I mean is, we will just drop out the lines starting with the mysqldump: that are causing us headache.\nWe achieve this by putting \u0026lsquo;mysqldump:\u0026rsquo; in a regexp that deletes any line starting with it as follows; '/mysqldump:/d'. It\u0026rsquo;s the lowercase \u0026rsquo;d\u0026rsquo; that does the business.\nsam@MizouziE:~$ gzip -cd ./Downloads/blogs.sql.gz | sed \u0026#39;/mysqldump:/d\u0026#39; | ssh \u0026lt;user\u0026gt;@\u0026lt;hostname\u0026gt; -A \u0026#34;mysql --init-command=\\\u0026#34;SET SESSION FOREIGN_KEY_CHECKS=0;\\\u0026#34; example_laravel_dummy\u0026#34; sam@MizouziE:~$ And look at that, no error! That means it worked.\nThere is one thing not entirely necessary here, though. If you spot it shoot me a DM on twitter @mizouzie\n8. Final check to make sure Now all that is left to do is check on our mysql instance on the remote server if everything is as we expect.\nMariaDB [example_laravel_dummy]\u0026gt; show tables; +------------------------------------+ | Tables_in_example_laravel_dummy | +------------------------------------+ | activity_log | | article_article | | article_author | | article_background_image | | article_category | | article_revisions | | article_site | | article_slugs | | articles | | author_revisions | | author_slugs | | authors | | background_images | | background_images_revisions | | blocks | | categories | | category_revisions | | category_site | | category_slugs | | failed_jobs | | features | | fileables | | files | | imports | | linked_images | | links | | mediables | | medias | | menu_revisions | | menus | | migrations | | password_resets | | provider_revisions | | provider_slugs | | providers | | ratings | | redirects | | related | | setting_translations | | settings | | site_revisions | | site_user | | sites | | slider_revisions | | sliders | | string_translation_revisions | | string_translations | | tagged | | tags | | twill_password_resets | | twill_users | | users | +------------------------------------+ 52 rows in set (0.001 sec) MariaDB [example_laravel_dummy]\u0026gt; ^DBye Nice, we have all our tables and then we exit with Ctrl + D.\nFinal working command After all our experimenting we got what we wanted, so our final command to do what we want looks like this:\nsam@MizouziE:~$ gzip -cd ./Downloads/blogs.sql.gz | sed \u0026#39;/mysqldump:/d\u0026#39; | ssh \u0026lt;user\u0026gt;@\u0026lt;hostname\u0026gt; -A \u0026#34;mysql example_laravel_dummy\u0026#34; So for any other use case, or just a a breakdown of each part, we had something like this:\n\u0026lt;user\u0026gt;@\u0026lt;localhost\u0026gt;:~$ gzip -cd \u0026lt;location/of/mysqldump.sql.gz\u0026gt; | sed \u0026#39;/\u0026lt;beginning of line to remove\u0026gt;/d\u0026#39; | ssh \u0026lt;user\u0026gt;@\u0026lt;hostname\u0026gt; -A \u0026#34;mysql \u0026lt;name_of_database\u0026gt;\u0026#34; So the command does this:\nUnzip the file Pipe the stream of the file output through sed Filter out undesired lines with sed Pipe the result of that to ssh With ssh execute the mysql command and feed the piped stream to a named database This all works because the zipped mysqldump file is essentially one big SQL statement that can recreate all tables and insert all data that was in the database it was taken from. They tend to be quite large files, hence the need to zip them.\nSummary This was a series of steps that ended up giving the desired results. There were probably a number of different ways to arrive at teh same conclusion, or even ways to arrive at a different conclusion that gave the same result. That is the cool thing about working in this field, we have a multitude of tools that can do small parts of a solution to a problem. It is up to us to do exercises like this to learn how to combine them into something that gives a result. That is what we software engineers get paid for. Practice problems like this, you\u0026rsquo;ll learn loads!\n","date":"2023-07-01","id":"fbae895a6dd2368ad09295f1d833e134","permalink":"https://www.mizouzie.dev/articles/mysql-database-migration-to-remote-server-from-gz-file/","summary":"Some bugs only appear when your web application is truly tested out in production. The actual use cases of your data structure may differ from what you imagined, so make a dump of the prod DB and play around on a development server.","tags":["mysql","tutorial","CLI","learning","linux"],"title":"MySQL Database Migration to a Remote Server from a .gz mysqldump file"},{"content":"\nThe Error - stream_socket_client unable to connect (connection timed out) After building a cool little app using Laravel which makes use of the fantastic (and seemingly dead simple) symfony/mailer and you want to send a simple email via SMTP directly from the app by setting up the necessary .env variables you will undoubtedly test it out on a local/dev environment and will hopefully see that it works very well. Now the fun part of deploying it to a production server using Hetzner\u0026rsquo;s great cloud services. Everything is set; apache/nginx, ssl, workers, the lot and the moment of truth arrives and you go through the actions to trigger an email being sent to your email address of choice.\nClick send.\nWait.\nWait some more.\nRefresh inbox\u0026hellip;\nStart to wonder\u0026hellip;\nWhy didn\u0026rsquo;t it send?\nAfter checking you set everything correctly you finally check the logs and see something like the above image. But why?\nThe Reason It is a timeout error on a standard PHP function stream_socket_client() which aims to create the secure socket between your application and the mail server so that you may start to send emails via your email server\u0026rsquo;s SMTP connection. It is an unusual error to encounter as it\u0026rsquo;s more common to just work or return a \u0026ldquo;connection refused\u0026rdquo; error, but in our case it just times out. There is not a great deal of feedback or evidence to point to why this is happening, but long story short, our request never even makes it out of our server.\nHetzner Firewall If you are like me, you wanted to save some CPU %s by utilizing the great firewall offered for free as a part of your Hetzner cloud account and have set up the firewall with various rules for incoming traffic and left it blank for outgoing traffic, which, according to the display window means that there are no restrictions whatsoever. In theory, that means that all outbound requests should be 100% unrestricted.\nThere is something we are not seeing here though.\nHetzner Documentation, or lack thereof There is apparently no (or very little) mention of the fact that Hetzner automatically block outbound ports 25 \u0026amp; 465. Find more details by clicking here.\nTL;DR Hetzner are savvy to scammers building spam email servers and just making people miserable by assaulting their inboxes until the IP is blocked so they do not allow any outbound traffic on these ports typically used for SMTP mail connections. Smart. But annoying they don\u0026rsquo;t really tell you until you delve into the support section of their site and notice they have a dropdown option for addressing this very specific problem.\nThe Solution So once you have found the super specific technical support like the below by clicking on your account icon in the top right and selecting Support from the dropdown menu:\nYou will then notice that there is a small mention of how you must send a request to have the ports unblocked and that is it. That is the solution. Send them a request via this dialogue box and after a short wait you\u0026rsquo;ll be able to send mail from your Laravel app hosted on a Hetzner server just like how you can in a local environment. Fantastic.\n","date":"2023-06-30","id":"d56763048c8ddf91ab280b39f450afdb","permalink":"https://www.mizouzie.dev/articles/send-smtp-mail-from-hetzner-server/","summary":"Laravel Mail Working locally but not on server. Getting stream_socket_client timeout error. We must allow outgoing TCP Connections in Hetzner Firewall.","tags":["PHP","web dev","documentation","Dev Ops"],"title":"Send SMTP Mail from Hetzner Server with Firewall"},{"content":"\nTypical places this arises Building an application in PHP with Laravel means that we can call on a great number of classes to do various parts of the overall process we wish to achieve. For the purposes of this example (and where I first came across this issue) we will look at writing tests for a Job Class. A job class is one which will be sent some data and then process that data in the background via a worker so that the application is free to continue processing other commands.\nA job class will often contain methods and variables that are;\npublic private protected As you can imagine, public methods are easy enough to test against as they are \u0026ldquo;exposed\u0026rdquo; to the outside of the class instance. It gets a little more difficult to gain access to these private and protected methods for testing, as they are intended to be called only by other methods within the class instance. They\u0026rsquo;ll be things like getters and setters so that a handle() function does not get clogged up with logic for retrieving it\u0026rsquo;s necessary data.\nWhen trying to run a test against such a class with private and protected methods, we will run into errors that look like the following two examples.\nError: Call to private Some\\ExampleClass::__construct() from scope Tests\\Feature\\Some\\ExampleClassTest What this error message is telling us is that we are trying to invoke a __construct() method inside the Some\\ExampleClass, which is not allowed from the scope of our test that may look something like the following:\nnamespace Tests\\Feature\\Some; class ExampleClassTest extends TestCase { /** @test */ public function my_job_does_something() { $job = new \\Some\\ExampleClass($input); // Make some assertions ... } } Just in that single line, we have already encountered the problem. If we look at the example class itself, we\u0026rsquo;ll see what trips us up:\n\u0026lt;?php declare(strict_types=1); namespace Some; final class ExampleClass { private function __construct( public readonly int $input, ) { } ... } Our attention should be drawn to the private function part. That constructor called on initiation CANNOT be called from outside of the namespace Some, we are trying to call it from Tests\\Feature\\Some\\ExampleClassTest.\nError: Call to protected method Some\\ExampleClass::exampleMethod() from scope Tests\\Feature\\Some\\ExampleClassTest This error is very similar to the above, just in this case we may have a public function __construct() so our class may be instantiated from outside, but our helper functions cannot be invoked outside of the handle() method. If we use the same example as above, we can get one step further before hitting a wall:\nnamespace Tests\\Feature\\Some; class ExampleClassTest extends TestCase { /** @test */ public function my_job_does_something() { $job = new \\Some\\ExampleClass($input); $result = $job-\u0026gt;exampleMethod(); // Make some assertions like... // $result-\u0026gt;assertEquals(\u0026#39;expected\u0026#39;, $result); ... } } So the class is created with no problem, but we want to test methods that are called from within the handle() method so we can be certain that the data being handled is the correct data.\nSolution: ReflectionClass Available in; PHP 5, PHP 7, PHP 8\nThe Reflection API in PHP is a way to retrieve any and all information from a class during runtime. The way we can use it in this case is to effectively make an instantiated \u0026ldquo;copy\u0026rdquo; of the real class we wish to test, \u0026ldquo;grab\u0026rdquo; the method we wish to test from the reflection of the class, and then tweak it ever so slightly to make the private function public so that we may use it from outside of the class which in this case, is from out test.\nSounds simple enough\u0026hellip;\nnew ReflectionClass($exampleClass) This first step is to create the reflection class on which we can make our needed modifications. There is actually a small pre-first step to take and that is to make a new instance of the class we wish to reflect and save it to a variable which we then use in our call to create a new ReflecionClass().\n$exampleClass = new ExampleClass($input); $reflection = new ReflectionClass($exampleClass); Now we have something to work with that is a little more malleable and we can decide next what we want from this reflection. Based on the previous examples of errors, let\u0026rsquo;s look at getting:\nthe __construct() or some named method like exampleMethod() getConstructor() To get the constructor (public or private) so that we can feed it with whatever values we need to test against, we have this handy function which may be used as such to set the __construct() of the class as a useable variable:\n$exampleClass = new ExampleClass($input); $reflection = new ReflectionClass($exampleClass); $constructor = $reflection-\u0026gt;getConstructor(); getMethod() To get the protected method that we wish to test against we have this method that can be used in a very similar way to the above:\n$exampleClass = new ExampleClass($input); $reflection = new ReflectionClass($exampleClass); $method = $reflection-\u0026gt;getMethod(\u0026#39;exampleMethod\u0026#39;); setAccessible() With both the the get helpers shown, all we are doing is saving the methods as they are to a variable. They haven\u0026rsquo;t yet been unlocked for us to use as we please, but this is where this method steps in and shows the real benefit of this whole process. As easily as this, we can change the methods accessibility so that future calls to it from our non-matching namespace do not set off any errors.\n$exampleClass = new ExampleClass($input); $reflection = new ReflectionClass($exampleClass); $method = $reflection-\u0026gt;getMethod(\u0026#39;exampleMethod\u0026#39;); $method-\u0026gt;setAccessible(true); invokeArgs() Now that we have a useable version of the protected/private method we wish to test the output of, we can call upon that method using this function which also feeds the method the needed parameters (arguments). Similarly to the setAccessible() we chain it on and it expects two arguments:\nThe object to invoke upon. (null can be used here in the case of static methods) An array of arguments that the method to be invoked expects. $exampleClass = new ExampleClass($input); $reflection = new ReflectionClass($exampleClass); $method = $reflection-\u0026gt;getMethod(\u0026#39;exampleMethod\u0026#39;); $method-\u0026gt;setAccessible(true); $result = $method-\u0026gt;invokeArgs($exampleClass, [$arg1, $arg2, ...]); // Make assertions against the resulting output like... // $this-\u0026gt;assertEquals(\u0026#39;expected result\u0026#39;, $result); Run your tests That\u0026rsquo;s it! After just a few extra lines of code, you are now able to make assertions in your PHPUnit test suites against otherwise inaccessible functions and you can sleep a little easier tonight knowing that the deepest trenches of your application are fully covered and there will not be any unwelcome bugs!\n\u0026hellip; at least not from the parts you wrote proper tests for.\n","date":"2023-05-13","id":"643ef61339145bbd491bc837292e7a2d","permalink":"https://www.mizouzie.dev/articles/how-to-test-protected-functions-with-phpunit/","summary":"An essential part of developing an app is testing your code. My preferred method of testing my Laravel code is using PHPUnit and this is how I use reflection to test those \u0026lsquo;harder to reach\u0026rsquo; protected and private methods inside classes.","tags":["web dev","laravel","learning","PHP"],"title":"How to test protected functions with PHPUnit in your Laravel app"},{"content":"\nI was very frustrated for more than a few minutes with this after installing the great Spatie package for permissions in a project I am working on that requires teams, roles and permissions. Click the link above to check out the documentation and you\u0026rsquo;ll see immediately the appeal it has for any Laravel developer.\nSidenote: These guys really do churn out an ever growing collection of the most helpful packages that will save you hours of thinking and development, so if you don\u0026rsquo;t know about them\u0026hellip; get to know!\nThe Error The error itself is the VSCode extension Intelephense, that is usually very helpful when writing PHP in VSCode, telling you that there is an error with an Undefined type ... after you have followed the steps outlined here in detail to install the permissions package on your Laravel app.\nWe have:\nUsed composer to pull in the package Manually registered the service provider Published migration and configuration files Adjusted to allow for teams Cleared the configuration cache Run the migrations Added the trait to out User model And BOOM!\u0026hellip; error.\nI tried composer dump-autoload, ./artisan config:clear (again), ./artisan config:optimize, all to no avail. Double checked I had followed all the steps\u0026hellip; I had. So??\nThe Solution The short answer is, there is no reason. But here is the solution. Just reload the window.\nCtrl + Shift + P // To open the editor commands // then type in or scroll down and select... \u0026gt;Developer:Reload Window It\u0026rsquo;s a simple as that. How annoying.\nCredit I need to shoutout Akshay K Nair for replying somewhere deep in a github issue and pointing me to this. I just hope that someone else finds this a lot easier than I did!\n","date":"2023-04-13","id":"0e08511c5bd2025690806653ad8d5f54","permalink":"https://www.mizouzie.dev/articles/undefined-type-spatie-permission/","summary":"VSCode with intelephense throws a strange and hard to debug error when using the spatie/laravel-permissions package even when you follow the docs to the letter. Here is how to fix it.","tags":["web dev","laravel","PHP","VSCode"],"title":"Undefined type 'Spatie\\Permission\\Models\\' . 'Permission' | 'Role' | 'HasRoles'"},{"content":"\nWhat are Spaces? Since the end of 2020, Twitter Spaces have been a feature of the social media platform, and while they\u0026rsquo;ve seen great popularity in some cases, some Tweeple may still not be making the most of the multitude of opportunities they can present.\nThe easiest way to describe them is to liken them to a hybrid of a public speaking forum at an international airport lounge in the guise of a podcast.\nHow they work A Space requires only one participant to exist, the Host, but the real magic happens when the host is joined by others in the form of Speakers and Listeners. The Space is given a title by the host that launched it and that will generally give an idea of the type of conversation that will be held between the host and speakers. The title is also what is displayed along with the names of the host and speakers in the Spaces section of Twitter so that potential participants can choose from the list of ongoing and upcoming talks.\nListening To listen, any user only needs to tap on a Space that tickles their fancy. This will open up a slightly larger tab showing more details of the Space and the current speakers and listener count. There you tap the Start Listening button to enter the Space and start streaming the audio from the room on your device.\nA listener is not restricted to zero input either. They have to ability to show animated emojis over their avatar should they wish to react to what they are hearing. It will show up for all users in the space, regardless of position.\nSpeaking To speak, a user that is already a participant in the Space can tap on the microphone icon in the bottom left corner to Request to Speak. This will send a notification to the Host/Co-hosts who will then be able to allow or deny your request to \u0026ldquo;join the stage\u0026rdquo;. Once on stage, the microphone icon becomes the control to toggle your device microphone on and off so that you can actually speak in the Space and be heard by all.\nIt is a good idea to make use of the raised hand emoji in the reactions panel when you are a speaker and await your turn to speak, normally granted by the host of the Space.\nHosting To host is to be the user that launched the Space in the first place. As host you pick the title, assign co-host and speaker status and generally oversee proceedings. Different people have different styles, so I would definitely recommend mixing it up a bit in other people\u0026rsquo;s Spaces to get a feel for how to manage a Space well (or not so well).\nAt the end of the day, you\u0026rsquo;re the boss in your own Space, so do what you see fit to keep the conversation flowing and let the value flow from exchanges between all participants.\nBenefits Humans are social creatures and we thrive from interacting with one another. The benefits of getting involved in conversations with other people are endless, but here I will try to give you the best reasons that I think you should grab the mic soon if you haven\u0026rsquo;t already.\nLearning My number 1 takeaway from the numerous Spaces that I have attended was learning. I learned a lot. I tend to get involved with Tech-Twitter Spaces and I have to say that my software development acumen has improved for it. Sitting back and soaking up knowledge by just eavesdropping on the convo between individuals held in high regard in their field alone has been like attending a mini university, but also getting involved and seizing the opportunity to actually ask those people questions that are relevant to my situation has been of unimaginable value.\nVariety of Thought My personal favourite feeling is when I think I know something, and then someone shows me a new angle on it and I feel like I\u0026rsquo;ve had the blinders taken off. Entering Spaces gives you the opportunity to meet people that share some huge similarities to yourself that also come from totally different walks of life. Exposure to new perspectives is what truly drives a deeper understanding, no matter the subject.\nBuilding Ideas A healthy, back-and-forth style conversation that builds on the similarities and differences of view on a topic can lead to amazing realisations for both those in the conversation and even those just listening. The way conversations can flow from one topic and sub-topic to another leads to connections being made that any one individual might not make by themselves.\nI love this because I am the type to obsess over something when I want to learn it and listening to knowledgeable people discuss an idea has often exposed every conceivable corner.\nPublic Speaking Practice Many of us wish to advance our career also. That\u0026rsquo;s very normal. A lot of higher stations require some form of team management and that means you need to be proficient in speaking to more than a few people at once.\nThat is daunting. More so if you have never done it.\nConquering Fears Spaces more often than not are actually Safe Spaces, run by compassionate people.\nThink about it. The people organising and speaking on these are giving up their time to give back to a community in some way. Each of these people have been a beginner at something at some point, they know how it can feel. I have always, always, always only ever seen hosts and co-hosts giving encouragement, time and (not a pun) space for a first time speaker to come onto the stage and address the audience in the room.\nImmediate Feedback If you are lucky enough to join one of the Spaces actually geared toward getting first-timers up to speak and introduce themselves, you may even get some immediate feedback on how you did that you can take away, think about and try to apply the next time you are up. If you are here from Tech-Twitter then you know about taking an iterative approach, and all iterations must start somewhere.\nNetworking Spaces are all about people talking to people. They are the definition of networking on a social network. Double network!\nProfessional A number of Spaces exist to not only get first-timers to pop their Space-Cherry, but to make themselves known to those that may be looking to connect with other developers. Some Spaces have gained a good reputation for this and getting up and introducing yourself has the potential to be as valuable as getting that golden opportunity of an elevator pitch with the CEO of that company you dream of working at.\nCasual Not all Spaces are mega-super-serious. Some are just for fun or just a little more of a casual style. If you show up consistently because you gel with a particular group that also show up consistently\u0026hellip; well, you\u0026rsquo;re very likely to become friends. On a site like Twitter that can only work in your favour, thanks to the algorithm noticing your relationships, you\u0026rsquo;ll all be shown each other\u0026rsquo;s content more often and be very likely to engage making each of you score a little higher on the Twit-o-meter. Fantastic.\nEntertainment Topics covered in spaces range from zero to absolutely everything. All kinds of things are discussed and go on in them and sometimes you\u0026rsquo;ll find them as engrossing as your favourite podcasts. I dare even say you might forget about your podcasts all together in favour of the live-action versions going on every day.\nWrap Up I have paid attention to spaces for a few months now, and I see so many improvements in my technical understanding with my work and so many improvements with how I use Twitter. I have listened to and even been a part of some amazing discussions and learnt what would have taken me a year of solid reading to learn in a matter of weeks.\nI see them as having huge value, especially when you compare joining a Twitter Space to, say, Netflix binging. It\u0026rsquo;s the same vibe if not more fun, but the benefits are tangible.\nWho to Watch out for I have a list of Twitter folks that will always draw me into a Space if I see their name on the roster, and I\u0026rsquo;d like to share them with you because they\u0026rsquo;re ultimately the reasons for me getting all these good things out of this feature.\n@AxelGarciaK and @hiro_codes These guys are always involved in great Spaces on topics like Real Programming (languages like C, Rust and Go), AI and making the most out of Twitter. I\u0026rsquo;ve gained tonnes of value from them and look forward to learning more from them. @GrahamTheDev This guy defines Dev Rel. Highly experienced, excellent succinct advice. Always around and open to questions. @ShawnBasquiat The host of one of the most valuable regular spaces in Tech-Twitter. Endlessly supportive. If you are gonna start somewhere, Shawn\u0026rsquo;s \u0026ldquo;THE HUNT\u0026rdquo; Space is where it should be. Of course, there are so, so many but I\u0026rsquo;d squash all the fun of exploration for you if I told you who else I enjoy talking with in these places! Obviously you should follow me too, @mizouzie, and join any Space you see me in and get involved. You will not regret it!\n","date":"2023-03-28","id":"031e7c2543b81ae11ee39a91233b689c","permalink":"https://www.mizouzie.dev/articles/space-is-the-place/","summary":"Space! The Final Frontier\u0026hellip; but what if it is the beginning? Twitter spaces are a great way to meet and trade ideas with people from across the globe from the comfort of your sofa!","tags":["web dev","learning","twitter"],"title":"Space is the Place: Reasons to explore Twitter Spaces"},{"content":"\nSenior Developers A senior developer has earned that title. They\u0026rsquo;ve waged wars and won, faced long days and nights, overcome the most obscure of obstacles. Now, for all their troubles they have to deal with you. Wet behind the ears and a danger if left unmonitored. Hardly seems fair, does it?\nThis is the curse of such a vast wealth of knowledge. They\u0026rsquo;ve built up so much over the years they can\u0026rsquo;t possibly apply it all at the same time. They must delegate to be efficient. How do they choose what to pass down the line and to whom? Well that\u0026rsquo;s all part of their new challenge.\nI\u0026rsquo;ve had some time now as a junior developer and I have been lucky enough to be under the care of a couple of seniors who have made my experience a very pleasant one, considering the mountain of varying knowledge I have acquired in such a short time. I want to point out the characteristics they display that I admire most and deeply appreciate.\nEssential traits Given that the responsibility of overseeing a project or even multiple projects is a stressful one, it is crazy to think that the senior developers of the tech industry also have to essentially baby-sit at the same time. A lot can go wrong even before they have to throw inexperienced developers into the mix. 3 of the most important traits for a successful senior developer to posses, in my opinion, are;\nAttentiveness Patience Optimism Let me explain to you, who like me, is the junior developer in this arrangement.\nAttentive I don\u0026rsquo;t mean they need to be all lovey-dovey and sweep your hair out of you eyes when you talk, I mean they need to pay attention even when it\u0026rsquo;s from afar. They need to have a good gauge of how you are feeling both in regard to your workload and in life in general. Not necessarily all the details of your every move, but are you happy?\nThe reason for this is that if you\u0026rsquo;re not happy, you won\u0026rsquo;t produce good work which means more work down the line because the code you commit is not good enough or within the deadlines. Simply checking in with you daily is all a good senior will do, but a great senior will take action when needed as they have the experience to be able to do so effectively.\nThe action does not have to be some grand gesture, sometimes just a few words of guidance or a \u0026ldquo;don\u0026rsquo;t worry, I still have days like that\u0026rdquo; go a very long way in helping an overwhelmed junior developer get a handle on things.\nPatient Often the team\u0026rsquo;s senior developer is the one that is really face to face with the deadlines. They see the whole project in the \u0026ldquo;big picture\u0026rdquo; sense so will also forsee the knock-on effects of a missed deadline before anyone else. Despite this burden, the best senior developers are able to balance the pressure while displaying great patience with their team, affording them the time needed to discover solutions in their own ways and therefore build themselves into stronger developers in the process. It is an investment that will only pay dividends in the future, but of course, our highly esteemed senior knows that already.\nA part of this patience is the ability to block the rage and fury of the dreaded (and often agitated) client. They soak up the barrage of questions like \u0026ldquo;well, why isn\u0026rsquo;t it done yet?\u0026rdquo; so that those in their care can keep a clear head and just focus on the task before them. They know that once deployment and delivery is accomplished, all that negative energy will evaporate anyway.\nOptimistic It is important to understand that this does not mean naive optimism. Programming requires an air of pragmatism, and years of thinking like that will lead to a senior developer being so inclined. The optimism I mean is a type of faith. Faith in their juniors to overcome the obstacles they need to, faith that they will ask if they really do get stuck and faith in their own abilities to provide the necessary learning resources and road maps to becoming a capable developer.\nIt is a type of self control that a father displays when their child first rides a bicycle without stabilizers. As much as they want to step in a protect, they know they must leave the space to fail in order for the kid to grow, to get stronger, better, to develop. They know if they can just hold off, it will pay off.\nSome examples I\u0026rsquo;ve had a terrible week this past week after having a project I delivered utterly trashed by the client and had to take it almost right back to the drawing board and implement a bunch of (front end) stuff that I am very unfamiliar and very very uncomfortable with. I wasted an entire week, if not more, trying out various JavaScript libraries to get an input form to perform more tricks than a circus and was seriously losing my mind over it. I couldn\u0026rsquo;t believe it was taking so long and just not progressing as well.\nI was angry. At both the situation and myself. My senior dev, however;\nnever swept in and bossed me around never complained about the amount of time I wasted checked in with me regularly afforded me the time to explore so many options As if that wasn\u0026rsquo;t enough, after about a week and without me even realising, he threw me a totally different small project that was in PHP which I am far more proficient in. I knocked that out in an afternoon, so he fed me a bonus task of dockerizing the application which I also managed relatively quickly. Two things, that if compared side by side with what I was so stuck on, would probably be considered slightly more advanced. It was definitely a morale boost.\nThe next day, same project and this time just looking into refactoring some SQL queries (which is a favourite of mine) and that had me feeling like bullets would bounce off me. I went back to the JavaScript that was torturing me, deleted the entire branch I\u0026rsquo;d spent a week tied up in and banged out a perfectly fine working solution in a couple of hours. Thanks to the previous day\u0026rsquo;s distraction techniques, I didn\u0026rsquo;t get hung up on the wasted time too!\nThanks to my senior\u0026rsquo;s attention, patience and faith in me I managed to eventually overcome something that I clearly wasn\u0026rsquo;t able to do a week ago, plus I have gained the experience that will hopefully help me avoid getting so caught up in a problem in the future.\nI\u0026rsquo;m grateful.\nCreated Environment You can see from just that one recent example that you have every right to be jealous of my working environment because my goodness, it is nurturing. Thanks to having this sort of support for the last 2 years, I can confidently say that I am more able as a developer than I should be for the number of years I have had in the industry. I have justifiable confidence because I have worked on real software used by some huge companies because I was not only taught the right stuff but given the opportunity to use that knowledge to build something that is a part of something of real significance.\nI look forward to working every day because it is always challenging but never frightening and because I can look back at what I\u0026rsquo;ve made and been a part of with pride. It is a great team to be a part of.\nResults I won\u0026rsquo;t repeat that I\u0026rsquo;ve gained a huge amount of experience in a short time\u0026hellip; but I really have. Not only that, though, I really believe that the future of the group I am a part of will be a great one because the next wave of junior developers after me are in for a solid support system and incredible guidance. This team has already achieved some great feats while getting little old me up to speed, so I can only see exponential success on the horizon.\n","date":"2023-03-24","id":"68a1dfa540a59b60a6552429019da224","permalink":"https://www.mizouzie.dev/articles/best-senior-developer/","summary":"Working under the care of a more experienced developer can make or break a junior developer\u0026rsquo;s career. Here are 3 things the best senior developers do.","tags":["web dev","career","productivity","learning"],"title":"3 things the best senior developers do"},{"content":"\nFormkit is a supercharger for developing applications on the already turbo platform of Laravel Inertia with Vue 3. It is a library of ready made components for building forms that make it very easy to construct any kind of form for retrieving user input. One of the features of this library that stood out the most for me was the Multi-Step forms.\nMulti-Step Forms So what is a multi-step form?\nIt is a format that breaks the usual monotony of filling out a form for the user. It splits the form into smaller form-lets that helps to give a much nicer UX because they\u0026rsquo;re not faced with such a huge list of questions all at once. The multi-step form can be split and navigated by tabs or a progress-map that resembles a London Underground map 😍\nSo as developers, we want to provide this kind of experience for our application users. Formkit is a very well provided for library with extensive documentation for it\u0026rsquo;s implementation into a standard Vue 3 project, but when I tried to put it into a Laravel Inertia app using Vue 3, it needed a little thinking outside of the dox.\nInstalling Formkit What do the docs say? Here you can check the Vue specific docs for the initial Formkit installation. They are nice and straightforward, but following these to the letter does not give us the desired result.\nWe will install with npm:\nnpm install @formkit/vue The slight difference for Inertia Now to get it working in our case, we need to have our app.js looking like this:\nimport \u0026#39;./bootstrap\u0026#39;; import \u0026#39;../css/app.css\u0026#39;; import { createApp, h } from \u0026#39;vue\u0026#39;; import { createInertiaApp } from \u0026#39;@inertiajs/vue3\u0026#39;; import { resolvePageComponent } from \u0026#39;laravel-vite-plugin/inertia-helpers\u0026#39;; import { ZiggyVue } from \u0026#39;../../vendor/tightenco/ziggy/dist/vue.m\u0026#39;; import { plugin as formkitPlugin, defaultConfig } from \u0026#39;@formkit/vue\u0026#39;; const appName = window.document.getElementsByTagName(\u0026#39;title\u0026#39;)[0]?.innerText || \u0026#39;Laravel\u0026#39;; createInertiaApp({ title: (title) =\u0026gt; `${title} - ${appName}`, resolve: (name) =\u0026gt; resolvePageComponent(`./Pages/${name}.vue`, import.meta.glob(\u0026#39;./Pages/**/*.vue\u0026#39;)), setup({ el, App, props, plugin }) { return createApp({ render: () =\u0026gt; h(App, props) }) .use(plugin) .use(ZiggyVue, Ziggy) .use(formkitPlugin, defaultConfig) .mount(el); }, progress: { color: \u0026#39;#4B5563\u0026#39;, }, }); The slight tweaks are evident on the import and then that same tweak is repeated inside the use() before the app is mounted.\nAs we need to import \u0026ldquo;plugin\u0026rdquo; from formkit and we already have a \u0026ldquo;plugin\u0026rdquo; named in our setup() function, it is necessary to give the Formkit imported \u0026ldquo;plugin\u0026rdquo; an alias. Then later down the chain of use()\u0026rsquo;s, we can provide that alias.\nInstalling Multi-Step addon What do the docs say? Here you can check the official docs for installing the Multi-Step addon for Formkit.\nTLDR: It suggests the use of a formkit.config.js file, which is fine if you\u0026rsquo;re just using Vue\u0026hellip; but we\u0026rsquo;re not!\nOne other thing to note, is that it\u0026rsquo;s not very obvious that you actually need to install this separately with:\nnpm i @formkit/addons The slight difference for Inertia As you may have noticed, we\u0026rsquo;ve seen a part of that before. The importing defaultConfig was in our first setup. We will use that to our advantage and do so inline stuff to get where we want to be.\nimport \u0026#39;./bootstrap\u0026#39;; import \u0026#39;../css/app.css\u0026#39;; import \u0026#39;@formkit/addons/css/multistep\u0026#39;; import { createApp, h } from \u0026#39;vue\u0026#39;; import { createInertiaApp } from \u0026#39;@inertiajs/vue3\u0026#39;; import { resolvePageComponent } from \u0026#39;laravel-vite-plugin/inertia-helpers\u0026#39;; import { ZiggyVue } from \u0026#39;../../vendor/tightenco/ziggy/dist/vue.m\u0026#39;; import { plugin as formkitPlugin, defaultConfig } from \u0026#39;@formkit/vue\u0026#39;; import { createMultiStepPlugin } from \u0026#39;@formkit/addons\u0026#39;; const appName = window.document.getElementsByTagName(\u0026#39;title\u0026#39;)[0]?.innerText || \u0026#39;Laravel\u0026#39;; createInertiaApp({ title: (title) =\u0026gt; `${title} - ${appName}`, resolve: (name) =\u0026gt; resolvePageComponent(`./Pages/${name}.vue`, import.meta.glob(\u0026#39;./Pages/**/*.vue\u0026#39;)), setup({ el, App, props, plugin }) { return createApp({ render: () =\u0026gt; h(App, props) }) .use(plugin) .use(ZiggyVue, Ziggy) .use(formkitPlugin, defaultConfig({ plugins: [createMultiStepPlugin()], })) .mount(el); }, progress: { color: \u0026#39;#4B5563\u0026#39;, }, }); As you can see, we\u0026rsquo;ve added;\na CSS import an addon module import that extra module inside the previously added defaultConfig Using Formkit Now that it is setup, we are free to use the super speedy form building tool to it\u0026rsquo;s fullest potential, stacking form sections in beautiful multi-step glory. For example:\n\u0026lt;script setup\u0026gt; import PrimaryButton from \u0026#39;@/Components/PrimaryButton.vue\u0026#39;; import SecondaryButton from \u0026#39;@/Components/SecondaryButton.vue\u0026#39;; import { FormKit } from \u0026#39;@formkit/vue\u0026#39;; function clearForm() { // Your clear form handler } function submitForm() { // Your submit handler } \u0026lt;/script\u0026gt; \u0026lt;template\u0026gt; \u0026lt;FormKit type=\u0026#34;form\u0026#34; :actions=\u0026#34;false\u0026#34;\u0026gt; \u0026lt;FormKit type=\u0026#34;multi-step\u0026#34; tab-style=\u0026#34;progress\u0026#34;\u0026gt; \u0026lt;FormKit type=\u0026#34;step\u0026#34; name=\u0026#34;csv\u0026#34;\u0026gt; \u0026lt;FormKit type=\u0026#34;file\u0026#34; label=\u0026#34;Spreadsheet\u0026#34; accept=\u0026#34;.xls,.xlsx,.csv,.txt\u0026#34; validation=\u0026#34;required\u0026#34; help=\u0026#34;Upload a csv, xls or xlsx file.\u0026#34; /\u0026gt; \u0026lt;div class=\u0026#34;my-6\u0026#34;\u0026gt; When a csv file is uploaded here, we will read the heading row so that you can choose from the list on the next section of this form which columns contain the variable values. \u0026lt;/div\u0026gt; \u0026lt;/FormKit\u0026gt; \u0026lt;FormKit type=\u0026#34;step\u0026#34; name=\u0026#34;columns\u0026#34;\u0026gt; \u0026lt;FormKit type=\u0026#34;text\u0026#34; label=\u0026#34;Columns\u0026#34; validation=\u0026#34;required\u0026#34; /\u0026gt; \u0026lt;/FormKit\u0026gt; \u0026lt;FormKit type=\u0026#34;step\u0026#34; name=\u0026#34;rows\u0026#34;\u0026gt; \u0026lt;FormKit type=\u0026#34;text\u0026#34; label=\u0026#34;Rows\u0026#34; validation=\u0026#34;required\u0026#34; /\u0026gt; \u0026lt;/FormKit\u0026gt; \u0026lt;FormKit type=\u0026#34;step\u0026#34; name=\u0026#34;maxLength\u0026#34;\u0026gt; \u0026lt;FormKit type=\u0026#34;number\u0026#34; label=\u0026#34;Max Length\u0026#34; :value=\u0026#34;500\u0026#34; validation=\u0026#34;required\u0026#34; /\u0026gt; \u0026lt;/FormKit\u0026gt; \u0026lt;FormKit type=\u0026#34;step\u0026#34; name=\u0026#34;submit\u0026#34;\u0026gt; \u0026lt;SecondaryButton :onClick=\u0026#34;clearForm\u0026#34;\u0026gt; Cancel \u0026lt;/SecondaryButton\u0026gt; \u0026lt;PrimaryButton :onclick=\u0026#34;submitForm\u0026#34;\u0026gt; Submit \u0026lt;/PrimaryButton\u0026gt; \u0026lt;/FormKit\u0026gt; \u0026lt;/FormKit\u0026gt; \u0026lt;/FormKit\u0026gt; \u0026lt;/template\u0026gt; For the full documentation on actually using Formkit (now that it\u0026rsquo;s working 😉) click here\nHappy Form-Building!\n","date":"2023-03-09","id":"ce6cead750e4e6377275fc21d2ecd7df","permalink":"https://www.mizouzie.dev/articles/how-to-unlock-formkit-multistep-forms-on-laravel-inertia-app-with-vue-3/","summary":"Formkit offers a great Multi-Step tool for building forms in your Vue app, but getting it to work inside a Laravel Inertia app is a little tricky. Here is how to get it running.","tags":["web dev","laravel","vue","inertia","formkit"],"title":"How to Unlock Formkit Multistep forms on a Laravel Inertia app with Vue 3"},{"content":"\nPHP Functions PHP is an arsenal of tools that can process data in a multitude of ways. This is one of the reasons that it powers ~75% of website server-side code. It is fast, has huge support and scales very well.\nIf you were to investigate how many core functions PHP has on v8.1.2 you would find:\n\u0026gt;\u0026gt;\u0026gt; $funcs = get_defined_functions(); =\u0026gt; [ \u0026#34;internal\u0026#34; =\u0026gt; [ \u0026#34;zend_version\u0026#34;, \u0026#34;func_num_args\u0026#34;, \u0026#34;func_get_arg\u0026#34;, \u0026#34;func_get_args\u0026#34;, \u0026#34;strlen\u0026#34;, \u0026#34;strcmp\u0026#34;, \u0026#34;strncmp\u0026#34;, \u0026#34;strcasecmp\u0026#34;, \u0026#34;strncasecmp\u0026#34;, \u0026#34;error_reporting\u0026#34;, \u0026#34;define\u0026#34;, \u0026#34;defined\u0026#34;, \u0026#34;get_class\u0026#34;, \u0026#34;get_called_class\u0026#34;, \u0026#34;get_parent_class\u0026#34;, \u0026#34;is_subclass_of\u0026#34;, \u0026#34;is_a\u0026#34;, \u0026#34;get_class_vars\u0026#34;, \u0026#34;get_object_vars\u0026#34;, \u0026#34;get_mangled_object_vars\u0026#34;, \u0026#34;get_class_methods\u0026#34;, : \u0026gt;\u0026gt;\u0026gt; echo count($funcs[\u0026#39;internal\u0026#39;]); =\u0026gt; 1735 That is not a small amount by any means, so it is impossible to know them all. Even the most experienced PHP developers will regularly refer to php.net to look up which they can use for what.\nWith 1735 functions being available, surely some must overlap or be similar. In this discussion we will look at the ones that seem like they could be the same thing and see if we can decide best use cases for each.\nMost commonly used Looking through Exakat\u0026rsquo;s top 100 php functions 2022, we can see a few likely candidates to choose from. Lets take:\nimplode() count() explode() trim() strtr() click on any to see the official definitions\nCompared to their closest cousins implode() vs join() Join is actually just an alias, so they\u0026rsquo;re exactly the same. Implode works like running:\nfunction implode(string $separator, array $arr): string { $imploded = \u0026#39;\u0026#39;; foreach ($arr as $index =\u0026gt; $str) { switch ($index) { case !0: $imploded .= $separator; default: $imploded .= $str; break; } } return $imploded; } Going through the steps above, it does something along the lines of:\nInitiate an empty string variable as $imploded Loop through the input array If the element of the array is at index 0, do not concatenate the separator to $imploded Otherwise concatenate given separator string Concatenate element to $imploded Repeat until all elements of array have been cycled Return fully constructed string $imploded count() vs if (!count()) This function has such high popularity due to it being used commonly for frontend \u0026ldquo;decision making\u0026rdquo;. When choosing whether or not to display a particular component depending on there being any instances of something in the backend database, developers will call count() on a parameter passed to the view being displayed. The idea is that if it returns a \u0026ldquo;truthy\u0026rdquo; value, as in not 0, then it confirms the existence of at least one instance that parameter in the database.\nThis can be fine for a single call and if there is not an enormous number of instances of that parameter. Often though, there will be a large number of conditional components which means multiple calls to count() which ends up counting an enormous amount of your database. This is not ideal for UX as it can make the page load excruciatingly slowly. There is a simple optimization demonstrated below:\n// Rather than calling count() on everything like so... \u0026lt;?php if ($param-\u0026gt;count()) { ?\u0026gt; \u0026lt;div\u0026gt;Show this example HTML component!\u0026lt;/div\u0026gt; \u0026lt;?php } else { ?\u0026gt; \u0026lt;div\u0026gt;Show alternate HTML or Nothing 🤷\u0026lt;/div\u0026gt; \u0026lt;?php } ?\u0026gt; // ...we can check NOT == 0 like this instead \u0026lt;?php if (!$param-\u0026gt;count()) { ?\u0026gt; \u0026lt;div\u0026gt;Show alternate HTML or Nothing 🤷\u0026lt;/div\u0026gt; \u0026lt;?php } else { ?\u0026gt; \u0026lt;div\u0026gt;Show this example HTML component!\u0026lt;/div\u0026gt; \u0026lt;?php } ?\u0026gt; The optimized second option flips the original and checks only for a non-falsey value which is satisfied by the very first counter beyond 0. After that first 1 is counted, the rest of the code can move on and display the non-existent case or the existent case accordingly. We are effectively only \u0026ldquo;counting\u0026rdquo; a maximum of the number of calls to count as opposed to counting the number of calls to count multiplied by the number of instances of the counted records in the database. That time can add up! Count one or zero and move on.\nexplode() vs str_split() vs str_tok() These functions are all about creating an iterable out of a given string, each splitting the string at a chosen point. The way that point is chosen differs depending on which function is called.\nexplode() searched through the string for a given sub-string and splits around that str_split() simply counts out the specified number of bytes (i.e. characters in the ASCII set) and divides the string there, then starts counting again from the split to find the next split location. str_tok() the same as explode() but does not return the whole split up string at once. The first two will return an array of the \u0026ldquo;pieces\u0026rdquo; of strings they have cut. This is handy when you need to derive a string from a url string, for example you can call:\n\u0026gt;\u0026gt;\u0026gt; $string = \u0026#34;https://mizouzie.dev/articles/that/help/developers/learn\u0026#34;; =\u0026gt; \u0026#34;https://mizouzie.dev/articles/that/help/developers/learn\u0026#34; \u0026gt;\u0026gt;\u0026gt; explode(\u0026#39;/\u0026#39;, $string); =\u0026gt; [ \u0026#34;https:\u0026#34;, \u0026#34;\u0026#34;, \u0026#34;mizouzie.dev\u0026#34;, \u0026#34;articles\u0026#34;, \u0026#34;that\u0026#34;, \u0026#34;help\u0026#34;, \u0026#34;developers\u0026#34;, \u0026#34;learn\u0026#34;, ] While with str_split() you will give an integer value (n) and it splits the string after each nth character.\nThe function str_tok() is the outlier here as it only returns the first section (or token, as the name suggests) on it\u0026rsquo;s first call. The interesting thing is that it will return the next section on the next call, and the next one only on the next call after that and so on until it has none left to return and returns false. This makes it ideal for use within a loop, as the returning of a falsey value will break out of the loop. It just removes the step of creating the iterable array to then do something with it. You can just get right down to business with this one.\ntrim() vs ltrim() vs rtrim() vs preg_replace() Trimming strings is a common necessity as many strings have invisible and undesirable baggage in the form of whitespace either lurking before or behind them. A string ending in a new line or carriage return character can wreak havoc on simple processing functions or scripts, so it is always wise to sanitize them with some sort of trim at the very least.\ntrim() indiscriminately removes whitespace from in front and behind a string ltrim() \u0026amp; rtirm() remove whitespace from the left and right of a string respectively preg_replace() requires a little knowhow of the dark-art of regular expressions Should you be familiar or at least comfortable with regex, you may specify exactly what type of whitespace is removed, where it is removed from or even only remove it given certain conditions. It is like the super-max-pro Premium fully licensed version of the trimming functions before it, as well as much more.\nstrtr() vs str_replace() For me, these two do the same thing. Search a string for a given substring, and then return that string with the substring replaced with a given alternative substring. Both accept arguments as strings or arrays, but there is a slight difference in how they accept the arrays.\nThe arrays passed to str_replace() (notice the plural arrays) will be one array of search values and a second array of the search value\u0026rsquo;s replacements. The search values and replacements will need to match up according to index in order to be executed properly.\nThe single array passed to strtr() feels like a shortcut as the index is the search value and the value is the replacement. i.e. ['from this' =\u0026gt; 'to that'].\nThe usefulness of this is determined by how you go about construction your arrays to be passed. In many cases it may be easier or faster to construct a single array with string indexes. For me, that option just feels more sensible, less room for error.\nSummary Now that we have looked at some of the most common similarities and differences, I hope you will consider yourself well armed and well informed on the great choice of incredibly powerful weapons at your disposal!\nNow go slay some data.\n","date":"2023-03-04","id":"ce827d43fa0631635b8aad31fb849589","permalink":"https://www.mizouzie.dev/articles/common-function-comparisons-in-php/","summary":"How do you decide between two functions that, at a glance, seem to do the same thing? Let\u0026rsquo;s pick apart the differences to try and make it easier.","tags":["web dev","PHP","learning"],"title":"Common Function Comparisons in PHP"},{"content":"\nGo, or Golang, is a wonderfully simple and robust language for building back end and data processing applications. In order to process data, we will need to know how to read data. Here are 3 different ways to achieve that before your application gets to crunching bytes.\nPackages Go is a modular language with a strong standard library. We\u0026rsquo;ll remain inside the realms of standard and still have a comfortable amount of options. The 2 packages that we\u0026rsquo;ll look at are:\n\u0026ldquo;os\u0026rdquo; Package os provides a platform-independent interface to operating system functionality.\n\u0026ldquo;bufio\u0026rdquo; Package bufio implements buffered Input/Output.\nEven though it is only two packages, there are at least three options here. The best part is that os is actually involved in all three.\nAdditionally, we\u0026rsquo;ll call on some helper functions from 2 other standard library packages just for niceties and a little formatting when passing variables:\n\u0026ldquo;fmt\u0026rdquo; \u0026ldquo;strings\u0026rdquo; Reading Input User input can come in a few forms. You may only need to set an environment variable like an API key or you may need to crawl through rows and rows of data in a spreadsheet. We can start small and simple.\nCLI Interaction: User Input The example above demonstrates an interactive app requesting that the user enters some input. When a relatively small value is needed, this is an easy way to get it. The user can input a string, press Enter and the application is able to read that string and do something with it. Let\u0026rsquo;s see how this works behind the scenes.\n./main.go\npackage reader import ( \u0026#34;bufio\u0026#34; \u0026#34;os\u0026#34; ) func Reader() *bufio.Reader { // Initiate user input reader reader := bufio.NewReader(os.Stdin) return reader } What we see here is the initialization of a new Reader type by the bufio package. This type is actually from the \u0026ldquo;io\u0026rdquo; package and it looks like this:\ntype Reader interface { Read(p []byte) (n int, err error) } Bufio wraps this type in a buffer which gathers and temporarily holds the data before sending it along the line all together as one object, rather than streaming it.\nWe also call upon the \u0026ldquo;os\u0026rdquo; package early on, in this case for the os.Stdin function which effectively stands for operating system Standard input. This is being called as the argument for the NewReader() function to tell the reader to accept input from the console.\nOnce created, this reader object has access to a few functions where you can specify exactly how it reads. We will use it to read the user\u0026rsquo;s input from the command line. To do so we call the ReadString() function, in which we have to specify the delimiter which tells the function \u0026ldquo;that\u0026rsquo;s the end\u0026rdquo;. Let\u0026rsquo;s build on what we had earlier.\n./main.go\npackage reader import ( \u0026#34;bufio\u0026#34; \u0026#34;os\u0026#34; \u0026#34;fmt\u0026#34; ) func Reader() string { // Initiate user input reader reader := bufio.NewReader(os.Stdin) // Print the instruction to the reader in the console fmt.Println(\u0026#34;Please enter your API key below:\u0026#34;) // Call the reader to read user\u0026#39;s input key, err := reader.ReadString(\u0026#39;\\n\u0026#39;) if err != nil { panic(err) } return key } So here we can see:\nAddition of \u0026ldquo;fmt\u0026rdquo; package just to print the prompt for the user Calling the reader to return to us the user\u0026rsquo;s input and an error ReadString() expects one argument which is the delimiter, in this case the byte for a new line \u0026lsquo;\\n\u0026rsquo; If the error is empty (nil) we have the string value stored in the variable key Return type for the function is now string This method of reading input is nice, quick and basic. Ideal for short string and integer values. What is also interesting is that you can combine it with another method when the data gets a little larger. We read a string, so what if that string was a path to a file? Maybe a csv file.\nFollow the Path: Read a File Nobody is going to sit and type out an entire huge data-set. We are building an application to make it faster and easier for the user to process data! So let\u0026rsquo;s read directly from a file. Say we used the first method to get a path to a config file and we have that string value saved in a variable\u0026hellip; what can we do with it? Call \u0026ldquo;os\u0026rdquo; yet again.\nmain.go\npackage reader import ( \u0026#34;bufio\u0026#34; \u0026#34;os\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;strings\u0026#34; ) func Reader() []byte { // Initiate user input reader reader := bufio.NewReader(os.Stdin) // Print the instruction to the reader in the console fmt.Println(\u0026#34;Please enter your config file path:\u0026#34;) // Call the reader to read user\u0026#39;s input path, err := reader.ReadString(\u0026#39;\\n\u0026#39;) if err != nil { panic(err) } // Read config file from trimmed path string file, err := os.ReadFile(strings.TrimSpace(path)) if err != nil { panic(err) } return file } What has been added?\nos.Readfile() that accepts a string as an argument. The string is the path we extracted from the user earlier We use the helper TrimSpace() from the \u0026ldquo;strings\u0026rdquo; package to remove and whitespace characters from the start or end of the provided path If the error if empty (nil) we have the read contents of the file pointed to by path Return type now []byte as ReadFile returns as a slice of bytes in the variable file This method helps to speed things up a great deal when there is a lot of data to feed into the application. There is a way, very similar to this, that we can open the file and read it line by line, but I will explain that in greater detail in another post as it allows you to do more interesting things when you involve loops and needs a little explanation regarding Reader types.\nExecutable Arguments: Feed it from the Start One huge benefit of Go is that it is compilable into binary files. This means that once it is written, you can export it as a stand alone program that can be run on another machine once installed. In the case of a CLI, it is often a good idea to build it to be able to accept arguments when being invoked. What this means is that you can set it that when a user runs the compiled program we\u0026rsquo;re building here, they can provide the input we need as argument following the invoking command. Like this.\nFor this example, it works almost exactly the same as reading the user input. Let\u0026rsquo;s go back to that simple code and see what difference there is.\nmain.go\npackage reader import ( \u0026#34;os\u0026#34; \u0026#34;strings\u0026#34; ) func Reader() []byte { // Get the path from the first argument path := os.Args[1] // Read config file from trimmed path string file, err := os.ReadFile(strings.TrimSpace(path)) if err != nil { panic(err) } return file } Here the difference is:\nCalling os.Args is all that is needed to access the array of arguments provided at the start That is assigned to a variable, which is then passed to our file reader function You may notice that we are calling index 1 on the array of os.Args and this is not a mistake. The reason for this is that the very first element of the array, index 0 is always the name of the program itself. The arguments actually begin from the second index position. It is possible to accept as many as you like, but be sure to add some sort of --help or manual for the tool if you are expecting a large number of variables to be passed this way. It is good practice to provide decent instructions anyway.\nSummary There you have it. Three great ways to accept data to be used, analyzed and manipulated by your Go CLI application. Each has it\u0026rsquo;s merits and best use cases, but at the end of the day it is up to you how and which you use. I tend to even include a combination and use nested if statements to check for presence/absence of one type or the other so that an appropriate prompt can be given or omitted.\nOf course, in this tutorial we have not looked at proper input sanitizing and the types of checks that can be done to ensure that a file/directory actually exists at the specified path. These are definitely a good idea to include in a real application as human error is a very real thing and a good application is a prepared application!\n","date":"2023-02-23","id":"70bd01458f467e2f663236f0350ee5e2","permalink":"https://www.mizouzie.dev/articles/3-ways-to-read-input-with-go-cli/","summary":"Tutorial with examples showing 3 different ways to read user input when building a command line interface (CLI) with Go","tags":["web dev","Golang","CLI","learning","tutorial"],"title":"3 ways to read input with a Go CLI"},{"content":"","date":"2023-02-21","id":"4e74f9d9a6d393fbc09d56de1dd93dc1","permalink":"https://www.mizouzie.dev/projects/ai-as-a-creator/","summary":"A project using the bi-products of an ongoing AI application development.","tags":["artificial intelligence","OpenAI","midjourney"],"title":"AI as a Creator"},{"content":"\nI am excited to announce the launch of a side-project that acts as a sort of recycling plant for the content I will be generating over the course of a current work project. It will be like a document to what I learn about interacting with the machine learning language model Davinci from OpenAI and the image generating model from Midjourney.\nI was really taken aback by the abilities of these tools, much like everyone else that have tried them, and when I was told that I would get free reign to try out the language model and build something off the back of it I was excited to say the least.\nThe Project The project itself I have named AI as a Creator and you can view the site here. The purpose of it is simply to show what comes out from the various prompts and re-tweaked prompts that I will be using while working with the model and also whatever images are produced when I go and have some fun with Midjourney.\nI am a huge fan of the static site generator Hugo and have used that to start this site with the help of a theme by Jan Raasch who I should probably apologise to because I removed the little \u0026ldquo;made with ♥ by Jan Raasch\u0026rdquo; from the footer because I couldn\u0026rsquo;t stand how it looked 🙈 I do, however, have it written down several times in my notes that if this even generates any revenue then I promise to pay a fair percentage towards their company.\nThe past The job that churns out the bi-product that I am to turn into this project has me writing an application in Go, which is fast becoming my second favourite language after SQL. As I am making small tweaks here and there I need to constantly test that the application behaves as expected and that involves interacting with the OpenAI API, which has a very nice library for use with Go and I must mention that it has been one of the most painless, if not one of the most down-right enjoyable experiences I\u0026rsquo;ve had since I began developing.\nIt has been surprisingly inexpensive to use too. The table below shows some of my whole team\u0026rsquo;s usage and even the biggest spike on the 10th of February where we tried to push the limits to see where the ceiling was ended up only costing $0.23 which is almost nothing!\nThe present The site itself is mostly a single page kind of thing, but there are a couple of supplementary pages for the moment that just provide a little extra context if desired.\nThere is not a huge amount of content thus far, but I thought it was enough to make a start. It was also a great excuse for me to practice my front end abilities even just in the realms of HTML, CSS and minimal JS. As a predominantly back end developer, I need to seize every opportunity I get! That mixed with my undeniable soft-spot for the arts meant that I just couldn\u0026rsquo;t sit on this pile of genuine creativity, it had to be shared.\nIt is a collection of:\nStories Poems Art Jokes Instructions The future I plan to keep on adding to it as the content piles up in my own computer, hoping that the quality of it also improves along the way even if I do already think the very first things I\u0026rsquo;ve generated are amazing to some degree.\nThe site will definitely be a rolling project and I already keep a notepad where I can scribble down ideas as they come to me. For example:\nEach of the entries should have a button at the bottom or the side that reveal the prompt that was used to generate that particular piece.\nEach entry should have a button to share just that entry, perhaps meaning that I will have to create an individual page for each entry and just display them all as one.\nThe possibilities are quite exciting and having a seemingly endless stream of content really takes the pressure off from having to write it like I write the articles on this site. I hope to explore and learn a great deal in terms of design, UI and UX.\nOutcome Honestly, I have no idea what the ultimate outcome will be. I\u0026rsquo;m certainly not holding my breath for any monetary gains as this is purely an artistic endevour and I\u0026rsquo;m already very happy with the things I\u0026rsquo;ve learnt about front end development just in these first two days.\nBut that is exactly it\u0026hellip; It\u0026rsquo;s just the first two days, so there couldn\u0026rsquo;t possibly be any way to tell what comes of this. All I can hope is that someone out there finds what has been produced as interesting and enjoyable as I do and will make my sharing it worthwhile.\nGo take a look and bookmark the page so you can check in after a while and see where this journey has taken the project. Or better yet, share this post with someone that you think would really enjoy what is on show.\n","date":"2023-02-20","id":"781f40b5b39d5db42fa64627bca25f80","permalink":"https://www.mizouzie.dev/articles/new-side-project-ai-as-a-creator/","summary":"Working with AI tools is taking the web development world by storm. This is how I plan to make use of it though.","tags":["web dev","artificial intelligence","OpenAI","midjourney"],"title":"New Side Project - AI as a Creator"},{"content":"","date":"2023-02-18","id":"fa06e2f6facedd6f81564e4a0929169f","permalink":"https://www.mizouzie.dev/projects/go-input-gist/","summary":"While building a CLI with Go, I ran a few little experiments without business logic to ensure that I was able to read user input exactly as expected.","tags":["Golang","learning","GitHub"],"title":"Go CLI User Input Experiment"},{"content":"Enkle Word Game A copy of the popular word puzzle game Wordle made with JavaScript and hosted on a static site.\nClick here to play! The idea Seeing that my young son was able to stare at his tablet screen for hours if not interupted, I wanted to make something to at least give him some sort of lesson while he played. All his games are simple, noisy and colourful. I found a nice tutorial on Laracasts that showed how to make a Wordle clone on the popular (and my favourite) framework Laravel, but after follwoing along I realised that the whole framework was unnecessary.\nStripped down I extracted all the JavaScript working logic from what I had built on the Laravel framework, and applied it to a standalone static site that could be hosted on GitHub pages for free.\nBuilt up After getting it working in it\u0026rsquo;s primitive form on a static site, and it was stable, I spent a little time developing it further and adding a few features so that my son wouldn\u0026rsquo;t get bored ofit too quickly.\nAdditions Beyond the standard 3x5 grid that the laracast tutorial shows you, I added a few buttons and features behind the scenes;\nAdd or reduce number of guesses, like a difficulty setting Choose the length of the word to guess from 3, 4 or 5 letters Each addition required a little extra on the JavaScript side of things as well as increasing the size of the library of words that the app uses. It was an interesting challenge.\n","date":"2023-02-17","id":"9c592bcf193c863adaf6ae10e0bd0f3e","permalink":"https://www.mizouzie.dev/projects/enkle-word-game/","summary":"A game built using JavaScript based on the same concepts as Wordle. Designed to be customizable for my young son to enjoy.","tags":["JavaScript","learning","GitHub"],"title":"Enkle Word Game"},{"content":" ","date":"2023-02-17","id":"0265d07e42e24778da57e26ad2d62a26","permalink":"https://www.mizouzie.dev/projects/seo-keyword-content-analysis/","summary":"This laravel application analyzes data gathered from your site and your competitor’s sites and gives you a comparative report to highlight where you are missing out on providing content that could help you to rank higher in search engine results. This is an example of the documentation I wrote during the development.","tags":["documentation","laravel"],"title":"SEO Keyword Content Analysis"},{"content":"\nThe Problem Working on an open source project is one of the best things a developer can do. The opportunities to learn and network are huge compared working on solo projects. The only way I can think of getting even more out of open source than contributing is to actually create and manage a project yourself. I tried this, early on in my career in tech and it was like strapping two great big rockets to my back. I started a project using NodeJS, which I was very inexperienced with at first, but within just a few months I had reviewed so many new things that I never would have seen if I just studied JavaScript by myself.\nThe project still exists today, it\u0026rsquo;s the news scraper API you can find by clicking here to go to my projects page. Before you do go and check it out, I can tell you that the thing I was most successful with was attracting new contributors. For such a basic project, we ended up having over 30 contributors. I want to share with you one of the key factors I believe helped us to reach that number.\nThe Solution To get attention, you need to draw eyes. I\u0026rsquo;m speaking particularly about drawing eyes on social media. When you share the project, GitHub will automatically make a generic image for the various platforms that looks just that\u0026hellip; generic. It will have the title of the project and a small version of your user profile picture, besides that are some statistics about the repo that are just too small to really see on a phone screen so are kind of a waste in my opinion.\nWhat you have the option to do, though, is add your own image to be used in the project repository\u0026rsquo;s homepage meta tags. The tags are the ones highlighted below, og:image \u0026amp; twitter:image:\nWhat those meta tags do is preload the image from the url in the content attribute for social media platforms that use open graph and for twitter. The result is the huge thumbnail, like the first screenshot at the top of this article, instead of the boring auto-generated-über-generic thumbnail.\nThe Image Being able to choose what image will appear on people\u0026rsquo;s twitter feeds and facebook/LinkedIn walls put you at an advantage, so seize it by choosing an eye-catching image.\nUse bright colours Have short, clear text Tempt passers by to click here now Try to keep the aspect ratio close to 1200 pixels x 627 pixels (1.91/1 ratio) The How When you have the right image you need to know where you can add it so that GitHub will store it and inject the url of the stored image into the landing pages \u0026lt;head\u0026gt;\u0026hellip;\u0026lt;/head\u0026gt; tags.\nClick on the Settings tab on the menu of your repository, and then scroll down tot he Social Preview section. Here you click on the Edit button to upload your image:\nThe Point That\u0026rsquo;s it. Done.\nNow, whenever a link to your repository is shared, a nice attractive image will fill the square and help to raise your click-rate. Be proud of your project, go show it off, go grab your next contributors by the eye-balls!\nSHARE! SHARE! SHARE!\n","date":"2023-02-16","id":"115c74cf0138a0a292f5c769a9023cc7","permalink":"https://www.mizouzie.dev/articles/make-your-github-project-stand-out/","summary":"Half the battle of progressing your open source project is getting it noticed and attracting contributors. So make the most of this simple trick.","tags":["web dev","meta tag","GitHub","open source"],"title":"How to make your GitHub project pop on social media"},{"content":"\nWhere I won\u0026rsquo;t use AI As you\u0026rsquo;ve probably already spotted, the image for this article is, in fact, an AI generated image. I will go into detail about the image itself later in this post, but I want to assure you that I am not trying to pull the wool over your eyes!\nWhat I mean when I say that I won\u0026rsquo;t use artificial intelligence is that I will not use it for any of the written content that you will find here in this blog. I want to keep all the written pieces here 100% from the inside of my own head so that it can continue to truly reflect my journey and my thoughts along the way. This is because I see language as a gift for conveying, transferring and even storing ideas, and without staying true to it being only my own actual production here, I will not be able to claim ownership over what is here.\nContrary to that, I don\u0026rsquo;t mind the images at all. In fact they\u0026rsquo;re quite fun to play around with and even reveal some interesting insights into our own psyche once you start to delve into the way we use the tools available.\nWhy I won\u0026rsquo;t use AI The reason behind me not wanting to use AI for this blog, besides the before mentioned view of \u0026ldquo;language is a gift\u0026rdquo;, is that I can already see the landscape changing, and with that, the value of the written word may well decline in my opinion.\nWe saw it with video content. The moniker of \u0026ldquo;YouTuber\u0026rdquo;, over the last 5-10 years became synonymous with being rich and famous. There was good reason for this as a great number of content creators made a decent living off of what they could earn through their channel when they had moderate numbers in the audience, and some have even had huge success in both status and earnings when their numbers went into the millions. There was enormous value to be reaped by those with the means to create content that garnered the attention that was efficiently converted in advert revenue, and rightly so! Back then it was not easy to create high-quality video content. Back then.\nNow, however, every man, woman and child (and even their dogs) have got a recording studio with built in editing suite in their pocket. Technology has come such a long way, so fast that almost anyone has the power to create a fortune at their fingertips. But that creates the age old problem that is the basis of economic studies, supply has over-run and the demand, even though it probably has also risen, just hasn\u0026rsquo;t done so to the same degree. This is evident in the way stars are born, burn bright for their 15 minutes, and then die out at an ever increasing rate because they\u0026rsquo;re so easily replaced. The churn rate makes your head spin.\nI fear that the written word is headed in the same direction because there is bound to be a huge influx of AI generated written content that is SEO super-charged just over the horizon. Part of the reason I think this is because I am working on tools at the moment to make it possible for people to ramp up their productivity 50 fold. It is possible, thanks to tools like the ones created by OpenAI, for a single person to generate the work of 50 in less than a day. Instead of writing entire articles, like this one, all that is required is a prompt alluding to such a piece and a machine that was trained on all the available written content out there in the world wide web, will understand that prompt and create something to fit. And it will be better than this, human-written article because it can calculate SEO targeted keywords and use them strategically to ensure that the article appears higher up in the search results than other articles on the same topic.\nThat sellable value is what has brought about the beginning of this gold rush.\nWho will use AI Businesses mostly. The aim of business in a capitalist society is to make profit. Profit comes from making sales and a business can only sell to those that know and want their product. The product is placed before those that need it by advertising. Advertising used to require seasoned professionals that would be worth their weight in gold, if not more, because they knew how to draw the attention of the masses that would spend on your businesses products. An article generated by artificial intelligence, that has been asked to focus on the SEO will now do just that at a cost so low I am surprised advertising agencies haven\u0026rsquo;t tried taking AI developers to court. The ultra-powerful articles can be generated for pennies.\nThe businesses cannot be blamed for this. I would dare to say they\u0026rsquo;d be foolish not to jump on this right away! But how long will it take for the value of these SEO focused articles to drop dramatically?\nWhat does it change? Ranking on Google is a comparative game. Each result is compared to it\u0026rsquo;s peers and listed accordingly. For the end user, who only wants good information, this is fantastic because it certifies that they\u0026rsquo;ll get the best information available. But if the first page of Google only shows 20 results and all at the same time 100 brand new articles about the same topic appear that all have tip-top SEO\u0026hellip; what happens then? Does the user of the search engine still end up with the best information?\nQuality The available information on the internet before this new wave of AI came automatically with an Open-Source-esque peer review, because if some source was publishing bad information, someone else, be it competitor or Karen, would put them on blast and cause public embarrassment. It kept things with an above 95% certainty and I think we may have taken those times for granted.\nPages like Wikipedia are perfect examples of how truth would just be he default as even when someone would put some false information, even as a joke, it would soon be corrected because we humans have an innate desire to be right all the time.\nQuantity More information, coupled with the risk of a decline in quality, is also not the best thing. The language models that will be used to generate this content will eventually be trained on the content created by the generation of machine learning before it and should some mis-truths get in there, who is to say where the compounding of errors will stop?\nI would definitely rather have one, very good and very accurate piece of information than five hundred vague or even slightly incorrect ones.\nWhat I have tried so far To this present date, I am yet to try out the text generating facilities available, but as I mentioned, I will be working with it heavily starting tomorrow and I still feel a little uneasy about contributing to this. But, it is the way things are going, so I had better not let myself get left behind.\nI have had a little play around with the image generating Midjourney, just today because I wanted to be annoying and use an AI image for a written piece about why I won\u0026rsquo;t use AI for my writing. Yes, I\u0026rsquo;m that kind of person. I will tell you what though, I was amazed by the results and had a lot of fun obtaining them!\nChatGPT I feel like I am the only person on all of twitter that hasn\u0026rsquo;t actually tried ChatGPT, but I will be changing that from tomorrow when I start working with it. I can however, direct you to click here for a very interesting video that my colleague made of interacting with it.\nHe also made a few articles with it\u0026rsquo;s help. Bouncing ideas off of it and turning the responses into a single article that you can find here which is interesting, but I found too many small discrepancies in the responses to give ChatGPT my full confidence. Still cool, but I just don\u0026rsquo;t rate it too highly.\nThere is a much stronger model called DaVinci, but I haven\u0026rsquo;t used that yet either.\nMidjourney So this thing can be fed prompts over Discord and if you take a few minutes to read over the documentation, it can do rather a lot and take an astounding amount of input. I wanted an image for this article of myself \u0026ldquo;standing out from the crowd\u0026rdquo; as that\u0026rsquo;s what I thought my stance on the subject kind of is because I have only seen social media giving these tools all the hype and praise you could imagine.\nI had a little browse through what other people had created for free in the newbie sections of the discord server, I also had a little look at one twitter account that I follow that shows AI images and sometimes hints at the prompts used. Click here to check them out. So after a little thought about what I wanted to represent with an image I thought to take my image from this site as I use it also on my own twitter account and add a little descriptive text prompt to spice it up:\n/imagine https://\u0026lt;url-to-image\u0026gt; standing alone and ignored in the middle of a darkened and bustling crowd, ultra realistic, golden hour, Leica 50mm, f1. 4, 8k And the result was the header image for this article. I though it was way cooler than I imagined it would come out. So of course, I had to do another one!\nThis time I went through a lot of prompts by others and found a photo of myself where I was dressed a little better. This also revealed a self-projection that perhaps I need to address, but nevertheless produced something that I must share and will probably use elsewhere:\n/imagine https://\u0026lt;url-to-image\u0026gt; as a male god stood surrounded by morbid sullen people, highly detailed, volumetrically lit, style of Alphonse Mucha and Beksiński, 8k, dark, intricate, 24mm lens, with intergalactic backdrop Which resulted in: Even if the cheeky sod aged me by 20 years (or 40 if you compare it to the first one!), I had to pause for a moment and appreciate that this is amazing. I told a machine a bunch of cool sounding stuff and it gave me back an even cooler looking image. I am a big fan of what kind of images people will be able to produce with this. I will definitely honing my prompting skills and playing with this again;\nonly for images with personal stuff but also for written content, cos it\u0026rsquo;s already become part of my job What was it old Abe Lincoln said?\nThe best way to predict the future, is to create it\nSo we\u0026rsquo;d better all get on out there and get creating.\n","date":"2023-02-14","id":"7cfbae45b7a4d948e022c5d2e6b06423","permalink":"https://www.mizouzie.dev/articles/why-i-wont-use-ai/","summary":"Artificial Intelligence is the hottest topic in a long while and we are certain to see it creep into content on the web. However, I will try to avoid the trend.","tags":["artificial intelligence","chatGPT","midjourney"],"title":"Why I won't use AI on this blog"},{"content":"\nWhat is Laravel Tinker? The short answer is that it\u0026rsquo;s a super power they give you when you boot up your Laravel application. All you type into the terminal:\n./artisan tinker OR EVEN... ./artisan tink This command boots up the built in REPL that is based on PsySH. REPL stands for; Read the user input, Evaluate the input, Print the resulting output and Loop back again to await further input. What kind of input and what kind of output though?\nInput The Tinker shell takes good old PHP. It\u0026rsquo;s like a little Laravel engine so it has every function within the framework at it\u0026rsquo;s disposal. It makes running logic wonderful thanks to how \u0026ldquo;fluent\u0026rdquo; the Laravel function naming is, you feel like you\u0026rsquo;re casting spells by speaking things into existence.\nOutput Typically you\u0026rsquo;re going to use Tinker for database interactions. You will be calling for eloquent collections or manipulating records on the database. When calling for eloquent collections, they\u0026rsquo;ll be displayed with all relevant information in a format similar to JSON. When making alterations to records, it will give you true, false or an error message.\nHow does Sam use Tinker? I imagine that I use Tinker in a similar way to most. The most common use case is when I am building controllers. Seeing as that is usually where the business logic lives. It is like my test-dummy. When I need to perform weird and wonderful things with my models outside of the bog-standard CRUD stuff.\nProofing Typically, I\u0026rsquo;ll use it to test out and confirm that I\u0026rsquo;ve use the correct relationships in my models. For example:\n\u0026lt;?php namespace App\\Models; class User extends Authenticatable { ... public function brand() { return $this-\u0026gt;belongsToMany(Brand::class); } public function sites() { return $this-\u0026gt;hasManyThrough(Site::class, Project::class); } } With a model like the above, some things I could run would look like:\nsam@MizouziE:~/code/laravel$ ./artisan tink Psy Shell v0.11.8 (PHP 8.1.2-1ubuntu2.10 — cli) by Justin Hileman \u0026gt;\u0026gt;\u0026gt; User::first()-\u0026gt;sites()-\u0026gt;count() =\u0026gt; 76 \u0026gt;\u0026gt;\u0026gt; User::first()-\u0026gt;sites()-\u0026gt;find(13) =\u0026gt; App\\Models\\Site {#4797 id: 13, site: \u0026#34;Rebeka\u0026#34;, url: \u0026#34;http://altenwerth.com/occaecati-magnam-molestias-hic-aperiam-qui-non-modi\u0026#34;, competitor: 1, project_id: 2, created_at: \u0026#34;2023-02-02 10:19:35\u0026#34;, updated_at: \u0026#34;2023-02-02 10:19:35\u0026#34;, brand_id: null, region_id: null, match_count: 0, opportunities_count: 0, gaps_count: 0, filename: null, laravel_through_key: 1, } \u0026gt;\u0026gt;\u0026gt; User::first()-\u0026gt;brand()-\u0026gt;first() =\u0026gt; App\\Models\\Brand {#4803 id: 1, brand: \u0026#34;NU BALANCE SPORTS\u0026#34;, key: \u0026#34;NBS\u0026#34;, created_at: \u0026#34;2023-01-20 12:02:50\u0026#34;, updated_at: \u0026#34;2023-01-20 12:09:45\u0026#34;, pivot: Illuminate\\Database\\Eloquent\\Relations\\Pivot {#4784 user_id: 1, brand_id: 1, }, } So the code entered for the input is just your run of the mill eloquent, and this is exactly how I confirm that the functions I write in my controllers are doing exactly what I want them to do. It saves me loads of time debugging when I forget to end my chains with a -\u0026gt;get() or something trivial like that.\nTweaking Another way I use it is to check that I get the desired results from a function in the database. I will often have the console open and a the table I wish to alter side by side, set a few variables in the Tinker session and copy + paste commands out of my controllers to ensure that the desired changes occur in my local development database. I find it best for spotting when I get relationships mixed up between belongsTo() and hasOne() or when I should have created a pivot table for example. This is facilitated by the excellent feedback you get from the error messages.\n\u0026gt;\u0026gt;\u0026gt; Brand::whereHas(\u0026#39;projects\u0026#39;)-\u0026gt;with(\u0026#39;sites\u0026#39;)-\u0026gt;where(\u0026#39;user_id\u0026#39;, 1)-\u0026gt;get() Illuminate\\Database\\QueryException with message \u0026#39;SQLSTATE[42S22]: Column not found: 1054 Unknown column \u0026#39;user_id\u0026#39; in \u0026#39;where clause\u0026#39; (SQL: select * from `brands` where exists (select * from `projects` inner join `brand_project` on `projects`.`id` = `brand_project`.`project_id` where `brands`.`id` = `brand_project`.`brand_id`) and `user_id` = 1)\u0026#39; \u0026gt;\u0026gt;\u0026gt; I now know that calling for a collection of brands that have projects, with the sites of said projects included, cannot be filtered further by user ID using a where clause. This is because the user_id column does not exist on the brands table. So, I will need to alter my code to achieve the desired collection. Thanks to the verbosity of Tinker!\nI can easily recall the previous input and tweak it and try again until I get back exactly what I am looking for.\nPadding My final most common use case is padding out my development database. Developing different actions within the app often calls for particular things to exist in the database, so I make use of model factories ran through the Tinker console to put some records in exactly as I need them before figuring out how to chop and change them. For example, if I need 2 users with the role of \u0026lsquo;admin\u0026rsquo;:\n\u0026gt;\u0026gt;\u0026gt; User::factory(2)-\u0026gt;create([\u0026#39;role\u0026#39; =\u0026gt; \u0026#39;admin\u0026#39;]) =\u0026gt; Illuminate\\Database\\Eloquent\\Collection {#4799 all: [ App\\Models\\User {#4891 name: \u0026#34;Mr. Lowell Skiles III\u0026#34;, email: \u0026#34;schaefer.ayana@example.net\u0026#34;, email_verified_at: \u0026#34;2023-02-08 09:52:40\u0026#34;, #password: \u0026#34;$2y$10$92IXUNpkjO0rOQ5byMi.Ye4oKoEa3Ro9llC/.og/at2.uheWG/igi\u0026#34;, #remember_token: \u0026#34;JqwJILGkjh\u0026#34;, role: \u0026#34;admin\u0026#34;, updated_at: \u0026#34;2023-02-08 09:52:40\u0026#34;, created_at: \u0026#34;2023-02-08 09:52:40\u0026#34;, id: 15, }, App\\Models\\User {#4784 name: \u0026#34;Ms. Kari Wyman\u0026#34;, email: \u0026#34;bboyer@example.com\u0026#34;, email_verified_at: \u0026#34;2023-02-08 09:52:40\u0026#34;, #password: \u0026#34;$2y$10$92IXUNpkjO0rOQ5byMi.Ye4oKoEa3Ro9llC/.og/at2.uheWG/igi\u0026#34;, #remember_token: \u0026#34;mIvodB7xnA\u0026#34;, role: \u0026#34;admin\u0026#34;, updated_at: \u0026#34;2023-02-08 09:52:40\u0026#34;, created_at: \u0026#34;2023-02-08 09:52:40\u0026#34;, id: 16, }, ], } Where can Tinker be used? So far we\u0026rsquo;ve only looked at using this tool in development and seen that it comes in useful in a number of ways. Some of these uses can come in handy in production also. Let me explain.\nSay you have a web application where users have access to shared information and private information. All the logic for showing and hiding data according to the authenticated user is in place and working fine, as well as having a role of \u0026ldquo;admin\u0026rdquo; that enables a user special privileges like being able to view all data and even some extra routes and views (i.e. and admin panel for making alterations to the data). However, there is no implementation of a way for an admin, or anyone for that matter, to toggle another user\u0026rsquo;s role from non-admin to admin or back. Now the site is growing in the number of users and you need help quickly to manage some data. What can you do?\nOne option is to go back to the code and implement that toggle function ASAP, passing tests and QA etc. Or you could use Tinker to quickly assign the role to another user directly on the server, providing you have ssh access. All you do once you are in the server is cd into the directory where your app lives and you can ./artisan tinker right there and use it just like we showed in earlier examples. Any changes made here will have the same effect like they would if your actual application were to make them as it is your application and therefore has all the database credentials and connections in place. Assigning the role to a user is as simple as running an update command using eloquent.\nOf course this approach can be considered a little risky, but I just wanted to highlight the possibilities available with this tool.\nWhat are the things they don\u0026rsquo;t tell you? Using this tool, like any other, gets better the more experience you have with it. So I want to share with you a few things that I only learnt after some time of using it so that you can have those benefits right away.\nUpdating classes If you have a Tinker session initiated, when changes are made in the codebase, they are not reflected immediately in the session. You will need to end the session, exiting by inputting q, and then restarting a new session. This is because it loads everything upon booting and does not have any \u0026ldquo;hot refresh\u0026rdquo; behaviour. This is not the hugest inconvenience. You also may have noticed in earlier examples that I was calling classes directly by name without specifying their namespace. This is thanks to Tinker\u0026rsquo;s aliasing.\n\u0026gt;\u0026gt;\u0026gt; User::first()-\u0026gt;sites()-\u0026gt;count() [!] Aliasing \u0026#39;User\u0026#39; to \u0026#39;App\\Models\\User\u0026#39; for this Tinker session. It does this with help of autoload.php the same way your application does when it is running. Sometimes, however, this doesn\u0026rsquo;t work right away especially if you have been making major changes to classes and namespaces. What you will need to do in order to get this automatic aliasing back is close Tinker and run:\ncomposer dump-autoload -o the -o flag optimises the autoload file\nAfter this, restart Tinker and you can call your classes by their first names, which saves a little time.\nUsing Faker/Faker inside Tinker As mentioned before, creating records on the fly is one of the most used things with Tinker. There will be times when you need to create things that may not already have a factory instance, so you can write a small factory right there. Often you will need the help of the Faker/Faker package, but that doesn\u0026rsquo;t work right out of the box. It must be imported and assigned to a variable, which is easily done within the Tinker shell by:\n\u0026gt;\u0026gt;\u0026gt; $faker = Faker\\Factory::create(); Now whenever it is needed, $faker can be called and chained with any of its methods for creating data to fill your database.\nTime savers The biggest time saver for me is assigning commonly used classes to variables, just like that example above with faker. I\u0026rsquo;ll often assign a $user = User::first() if I know I will be repeatedly calling on a single user instance.\nThe only thing with variables is that they do not persist from session to session. If you close Tinker, you will lose all variables assigned during that session. However the history will be available between sessions, so in true \u0026ldquo;terminal user\u0026rdquo; fashion, you can find all your previously entered commands by hitting the ↑ key (\u0026hellip;repeatedly).\nWrap up All in all, I think it is safe to say that if you are developing a Laravel application, you absolutely must have a go with Tinker. Laravel has such huge popularity mostly due to it\u0026rsquo;s ease of use and streamlined features like the plethora of ./artisan commands, and Tinker is one of them but more of an actual super power. So go, make use of it! Build amazing things at break-necking pace! It\u0026rsquo;s all there for you.\n","date":"2023-02-08","id":"c4207643dc6d2a6ec8da708afa8baf86","permalink":"https://www.mizouzie.dev/articles/developing-a-laravel-app-using-tinker/","summary":"The Laravel framework has a huge amount of helpful features, let\u0026rsquo;s take a deeper look at one of the most powerful. Tinker.","tags":["web dev","laravel","productivity"],"title":"Developing a Laravel Application using Tinker"},{"content":"Energy Price News API A project to create a public API that scrapes news sites for anything concerning the changes in energy prices.\nThis project\u0026rsquo;s secondary aim is to help beginners learn how to contribute to open source projects and will be purposely kept as basic as possible.\nUp to date version hosted at: RapidAPI Hub\nClick here to see the site! Original Idea This project was first thought up after watching this video by Ania Kubów, so many thanks to her for the inspiration. Be sure to check the channel out for more easy to follow tutorials!\nPlanned Features Links to articles End points for specific sources Thorough documentation An open and inviting issue-board to encourage discussion of future features Language \u0026amp; Prerequisites Javascript primarily, therefore: Node.js \u0026gt;v16 NPM A browser extension for viewing JSON is helpful like JSON Formatter Warning The above mentioned Node version is important to be able to run this project properly as it makes use of some newer functions. Also, if you are not using linux, the JSON formatter browser extension is HIGHLY recommended.\nInstallation Fork this repo and then clone your fork to an empty local directory using SSH run: npm install Now the basis of the project is here and can already be viewed by running: npm run dev You may view the various endpoints by opening localhost:8000 in your browser and appending the desired route e.g. localhost:8000/api/news Contribution The aim for this project it to be very easy to access, so please have a look through the contribution guide if you need an idea how or where to get started.\nAPI documentation Some rudimentary and development focused documentation on using the API can be found here, where you have listed the various endpoints available and how to make use of any additional features.\nContributors ✨ Thanks goes to these wonderful people (emoji key):\nSoshun Esaki\n💻 nulad\n💻 🤔 takanome_dev\n💻 ⚠️ 🤔 📖 🚇 🔧 🔬 👀 💬 🚧 📆 👀 AyushiN\n💻 Yoshemith Castellanos Irribarren\n💻 🤔 🚇 🖋 🎨 dbsaw\n💻 🤔 Diego Cordoba\n💻 Anu\n📖 James Neff\n💻 Jon Rutter\n💻 Roberto\n💻 🤔 Elmir Ismayilov\n💻 Ramón Soria\n💻 alesbe\n💻 🐛 kvaithin\n💻 apurva-hub\n💻 cfkim\n💻 🤔 Ghada\n💻 Klesta Luli\n💻 Jayavardhan\n💻 Dalu46\n💻 Ian\n💻 Muiz Uvais\n💻 scottjwilson\n💻 🔌 k-puchala\n💻 snehashish-ghosh98\n💻 nomandhoni-cs\n💻 Rohan Nair\n💻 mrajen27\n💻 Ketan Parmar\n💻 Z Adil Khwaja\n💻 MuminAhmadKhan\n💻 Stefan Talbot\n💻 🤔 Dev Parikh\n💻 Will12\n💻 💡 Rupali Haldiya\n🐛 Ashwin Acharya\n💻 Leon Lafayette\n💻 🤔 🔬 ⚠️ Sayam Gandhak\n💻 ⚠️ reny_pacheco\n💻 ⚠️ 🤔 ChinmayKumbhare\n💻 Chandan Kumar Mandal\n💻 Hamza Nawab\n💻 ⚠️ Andres Cespedes Morales\n🚧 Madalin Ignisca\n🚇 🧑‍🏫 Artur Bauer\n💻 Aabhas Sao 💻 Susanna\n💻 Ignacio Alvarado\n💻 This project follows the all-contributors specification. Contributions of any kind welcome!\n","date":"2023-02-05","id":"af068f420367c9443104ea4734e17e96","permalink":"https://www.mizouzie.dev/projects/energy-price-news/","summary":"A project to create a public API that scrapes news sites for anything concerning the changes in energy prices.","tags":["open source","api","nodeJS","GitHub"],"title":"Energy Price News API"},{"content":"\nSections\nWhat is Docker Docker is a tool used to create what are known as containers, yes you can imagine it like a shipping container on a cargo ship (hence the company\u0026rsquo;s logo/mascot, Moby). The containers themselves are like small virtual machines that run a specific package of software that is defined by something called an image. The image tells Docker exactly what the small virtual machine needs to be and do and Docker creates a software only version of exactly that which runs on your host machine but still completely separate from your machine. You could consider it a separate node on a network that only the host machine can have access to. I say can have access because if you want to be able to communicate with the container, you will need to have a network set up, but we will look at this later.\nWhat database can be used? For the sake of this article, we will use MariaDB as our database example, but you could apply most of the theory we\u0026rsquo;ll cover to any database of your choosing. I am a back-end-leaning-full-stack kind of developer, so my personal favourite is relational SQL over NoSQL, and although MySQL is the industry standard, I personally prefer to use MariaDB whenever possible because it\u0026rsquo;s open source and I\u0026rsquo;ll choose open source over corporations any day.\nWhatever your choice of database, there will be an image for you to pull and work from where the set up steps will;\nbe very similar to what we will go over here any differences will be apparent when you read the necessary docs, because we all RTFM, right?\u0026hellip; How does a MariaDB container work? Like we saw before, the MariaDB container will just be like a stand-alone computer on the network that runs the version of MariaDB that you specify when you provide Docker with the image that you desire. If you take a look at the official documentation for tags, you will see pages and pages of different versions that are available to suit any need imaginable.\nThe official docs also give nice and clear instructions on setting up a basic instance, but I remember that the very first time I read them and followed them, I did not exactly know what I was doing or why it worked. I aim to make all that clear below!\nHow to set it up from the terminal Firstly, we are going to skip over the installation process for docker, which you can find help with here if you have not already done that.\nNow we will look at the basic command provided by the documentation and break down what each part is doing.\ndocker run --detach --name mariadb-container --env MARIADB_USER=mizouzie --env MARIADB_PASSWORD=mizouzie_loves_mariadb --env MARIADB_ROOT_PASSWORD=root -p 3306 -v mariadb-volume mariadb:latest command / option explanation docker tells docker that we are talking to it, like shouting \u0026lsquo;Hey!\u0026rsquo; run we want what follows to be run BY docker --detach flag to say \u0026lsquo;please carry this out in the background and don\u0026rsquo;t occupy the terminal\u0026rsquo; (the short version is -d) --name the string following this flag will be assigned as the container name --env the string following should be added as an environment variable, handy for passwords etc (the short version is -e) -p specify which port(s) to expose to the host machine -v create and specify the name of the volume for this container mariadb:latest the name and version of the image you wish docker to pull Some things to note After running this command with all you own details, docker will first check your local images for the one you have specified. If it doesn\u0026rsquo;t find it already downloaded, it will then pull the image from docker hub and use that to build the container with any and all of your given arguments like the environment variables and name.\nThe container will now be running and will not stop until you tell it to, which can be done by:\ndocker stop \u0026lt;the-name-you-gave-the-container\u0026gt; The container will be accessible by a default network known as a bridge. You can read details of the network and other useful information about the container by running:\ndocker inspect \u0026lt;the-name-you-gave-the-container\u0026gt; The huge display of information after running this command can seem daunting, but just make the terminal full screen and go through the layers one by one and you will soon start to understand the way these containers work. You will spot the environment variables you passed to it earlier, as well as all imaginable configuration key:value pairs which will mostly be set to whatever their default is, but all that is customizable if you wish to delve into the documentation.\nIf you just want to know what port you can access the container on you can use grep, for example:\ndocker inspect \u0026lt;the-name-you-gave-the-container\u0026gt; | grep HostPort The -v flag to create a volume is an essential step if you want to be able to save data between stopping and starting the container. Omitting this means that on every stop/start, any data that was inserted into the database previously will be gone. Seeing as the point of a database is to store data, it\u0026rsquo;s a good idea not to miss this out.\nOther services that work well with it It\u0026rsquo;s all good and well having our database instance running, but while we are developing applications we often need to be able to peer inside or even feed in some raw SQL commands.\nThe official image docs show how to connect a MySQL command line client, so again we\u0026rsquo;ll break down what means what.\ndocker run -it --network some-network --rm mariadb mariadb -hmariadb-container -umizouzie -p command / option explanation docker tells docker that we are talking to it, like shouting \u0026lsquo;Hey!\u0026rsquo; run we want what follows to be run BY docker -it tells docker to keep an interactive terminal open to allow us to actually use the connection --network the name of the network the desired container is on, therefore we wish to join (don\u0026rsquo;t worry, we will talk about these below) --rm remove this container once it is closed mariadb mariadb the first is the image we\u0026rsquo;re using, the second is the command to run this container against the running container and connect using the following arguments -h the name of the host container must match what you put earlier -u the name of the user we want to connect as, equal to the MARIADB_USER environment variable must match what you put earlier -p upon creating the container, prompt me for the password which will be equal to the MARIADB_PASSWORD environment variable Notice that the -u, -h \u0026amp; -p flags come after specifying the container? That is because they are \u0026ldquo;arguments\u0026rdquo; for the container itself rather than \u0026ldquo;options\u0026rdquo; for the command. Don\u0026rsquo;t mix up the -p with the port exposing option from earlier!\nThey also have a slightly different syntax in which there is no space between the flag and it\u0026rsquo;s value.\nThis will open up MySQL client right there in the terminal and you can interact with your database.\nHowever\u0026hellip; I find this a little cumbersome for smooth development, so I much prefer to use Adminer, which as you may have guessed by now, can be spun up in it\u0026rsquo;s very own container. The setup is similar to how we set up the MariaDB container and you can check out the official docs for the details should you want to set it up in the terminal too. The only problem with doing this is that you must set up a named network and connect both the MariaDB container and the Adminer container to it so that they can communicate. I did it a few times just to see how it was, and it\u0026rsquo;s a lot of work so I\u0026rsquo;ll just briefly explain the part of creating a network, because you will see later that there is a much easier way to achieve the same results even if doing it all manually is far more educational.\nNetworking containers Keeping things separate is kind of the essence of docker containers, but they\u0026rsquo;re not much use if they can\u0026rsquo;t communicate with one another. This is nice and straightforward to achieve by networking.\nUpon creating the MariaDB container above, it automatically made a bridge network with the host machine to expose the ports found by searching through the output of docker inspect, which is typically 3306, but was 5000 in our example. It gets a little out of that scope when we want to connect another service to both the MariaDB container and our host machine. This is where we must create a network which will connect all three.\nNetworking in docker treats the network itself as a container that you can add other containers to. The only difference is that it is noticeably more simple to set up. Just the following command, and we\u0026rsquo;re good to go:\ndocker network create \u0026lt;name-of-your-network\u0026gt; Now that the network exists, it gives us the option to connect a container to it during the docker run command by using the --network flag and naming this newly created network, or it is possible to add a running container by using:\ndocker network connect \u0026lt;name-of-your-network\u0026gt; \u0026lt;name-of-your-container\u0026gt; Once the database is added to the network, you can add whatever method of interacting with it you choose using the same method.\nHow to set it all up with docker compose There is a much more simple way to do all of what we have discussed in one go. Creating a file named docker-compose.yaml inside our working directory. This is like an instruction script for automating all the terminal commands we just painstakingly typed out. Now that we know the ins and outs of all the commands, we should be able to read through the file and know what is doing what. Here is an example:\nversion: \u0026#34;3\u0026#34; services: mariadb: image: mariadb:10.7 environment: - MARIADB_ROOT_PASSWORD=root - MARIADB_DATABASE=example_database - MARIADB_USER=mizouzie - MARIADB_PASSWORD=mizouzie_loves_mariadb - MARIADB_AUTO_UPGRADE=true volumes: - mariadb-volume:/var/lib/mysql ports: - \u0026#34;3306:3306\u0026#34; adminer: image: adminer:latest environment: - ADMINER_DEFAULT_SERVER=mariadb ports: - \u0026#34;8080:8080\u0026#34; volumes: mariadb-volume: Once we have this file present in our working directory, it can be called using a built in feature of docker called compose. This feature used to be a separate thing to docker, but it has been fully integrated into the docker CLI and this makes things wonderfully easy for us. A simple command of,\ndocker compose up -d run from the terminal inside our working directory tells docker to look for a file named docker-compose.yaml, read it\u0026rsquo;s instructions, and spin up the containers with all the options included within the file. If you noticed the -d option at the end there, that is the same --detach flag we used earlier that tells docker to run it in the background and free up the terminal.\nAdditionally to setting up the containers from the file, docker will do a couple of things automatically;\nCreate a network container for the listed containers so that they may all communicate immediately. Prepend the name of the working directory to the container (and network) names This are handy because not only does it save you the trouble of setting up networks and making connections manually, but you can easily copy + paste the same yaml file between projects and use it again without worrying that your containers will overwrite one another.\nStopping and starting containers Whether we start containers via the command line or a yaml file, once they are running it is easy to stop and start them as we please. We only need to make use of 3 simple commands to get the needed information and give the desired instructions. The below example shows 2 of these commands and the expected outputs:\nsam@MizouziE:~/code$ docker run --detach --name mariadb-container --env MARIADB_USER=mizouzie --env MARIADB_PASSWORD=mizouzie_loves_mariadb --env MARIADB_ROOT_PASSWORD=root -p 5000 mariadb:10.7 36cef2546991c8c21e2011d0cc678026fc7258f4f922fea9d4aabfa0d4611815 sam@MizouziE:~/code$ docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 36cef2546991 mariadb:10.7 \u0026#34;docker-entrypoint.s…\u0026#34; 4 seconds ago Up 3 seconds 3306/tcp, 0.0.0.0:32768-\u0026gt;5000/tcp, :::32768-\u0026gt;5000/tcp mariadb-container sam@MizouziE:~/code$ docker stop mariadb-container mariadb-container First we create a container The output is the long ID of the created container Use docker ps The output a list of any running containers with the most important details Use docker stop \u0026lt;container-name-OR-container-ID\u0026gt; to stop that container The output is the name of the stopped container After stopping the container, run docker ps again and we\u0026rsquo;ll see that the specified container is no longer present in the list, but the container and all of it\u0026rsquo;s data does still exist and can be restarted whenever desired. To restart a created container:\ndocker start \u0026lt;container-name-OR-container-ID\u0026gt; Even if we forget the name or ID of a container we closed a while back, so long as we have not removed or pruned it from our system, we can call docker container ls -a to see a list of every container we have whether they are running or stopped.\nHow I keep it organised One of the gripes that a lot of people have with docker is managing it. The levels of complexity introduced by the lashings of automation can make your machine choke when things get cluttered, but with a little further understanding it can be managed and painless. This tweet represents my approach.\nBoilerplate docker-compose.yaml Opt for the DRY approach and write yourself a reusable yaml file. As stated before, cross-contamination is avoided automatically with the naming conventions, so using the same boilerplate over and over is no problem. It makes it very easy for you to alter small details like the version between projects which is probably the main advantage of using docker for databases in the first place.\nThis also makes it easy to micro-manage things like the storage should you wish to override docker\u0026rsquo;s automatic volumes allocation.\nStorage management I once ran into issues with docker filling up my hard drive partition because I always left it to automatically use \u0026ldquo;volumes\u0026rdquo;. These are great for ease of use, but after running multiple containers with large volumes, it can take up too much space. The problem comes from docker persisting data inside it\u0026rsquo;s self-managed volumes which are associated with a container and sometimes removing a container does not remove the volume also, so it just sits there rent-free. To remove these freeloaders use:\ndocker volume prune With that, any volume that exists but is not associated with a container will be destroyed. Bear in mind that you will loose any data if you are in between removing and rebuilding a certain container that you wish to reuse the old volume with.\nAnother way to avoid volume clutter is to tell docker to use bind-mount instead of automatic volumes. This can be done through the command line or more easily in the yaml file. Here is the same example from before, but with a customised bind mount path:\nversion: \u0026#34;3\u0026#34; services: mariadb: image: mariadb:10.7 environment: - MARIADB_ROOT_PASSWORD=root - MARIADB_DATABASE=developer - MARIADB_USER=developer - MARIADB_PASSWORD=developer - MARIADB_AUTO_UPGRADE=true volumes: - type: bind source: ~/../../usr/epn-api-db target: /var/lib/mysql ports: - \u0026#34;${FORWARD_DB_PORT:-3306}:3306\u0026#34; adminer: image: adminer:latest environment: - ADMINER_DEFAULT_SERVER=mariadb ports: - \u0026#34;8080:8080\u0026#34; volumes: mysql: Under volumes we can specify the type and give a source and target as arguments. What this does is makes a tunnel from the container (path inside container = target) to the host machine (relative path on host = source). This approach effectively renders the container as only a software layer and uses the storage on your machine the same way the software would if it were running on your machine.\nSome things to consider using this approach\nThere is an issue of permissions when using this that will need to be set up for it to work Changing/deleting/corrupting this data on the host will be reflected in the container I do use this approach because I like to have full control, but it is advisable and more convenient to leave docker to manage it automatically. Just be sure to do housekeeping once in a while and clear out the dangling volumes.\nBenefits over local installation of MariaDB Although it feels at first as a lot to learn, what it boils down to is having yourself a simple setup that can be used time and time again. This is absolutely ideal when you work with multiple projects that use different versions or even different database management systems altogether because it\u0026rsquo;s only required to modify a line or two of a template file and you can have the exact needed version of the exact needed system in seconds without ever installing and configuring on your machine.\nAlso as a lot of applications are deployed to production using docker, so having a local development repository with as close to production environment variables is always a plus.\nI am not against having a DBMS installed locally at all, but having one also means that it needs to be managed and upgraded by you, whereas using prefabricated recipes from the open source community means that you can simply always start with the optimal setup.\nSummary In closing, I think that docker is the perfect tool for database management within your projects and as a database is more often than not the essential foundation for an application or website, learning and using this approach is the perfect foot-in-the-door for any developer to see the expansive landscape of what docker is capable of. In all that we have detailed out and explained here, we\u0026rsquo;ve barely touched on even 1% of what can be done.\nI honestly urge you to try it out with your next project, because after a while of using it you will begin to see that so much is possible thanks to this platform.\n","date":"2023-02-05","id":"8727c39abf31507437decd70f5b2f97e","permalink":"https://www.mizouzie.dev/articles/why-use-docker-for-databases-and-how/","summary":"Docker is an invaluable piece to add to any tech stack for a multitude of reasons, but it can often be confusing to work with. Here we\u0026rsquo;ll dive into my favourite way to use Docker containers and explain every step   .","tags":["web dev","docker","learning"],"title":"Why use Docker for databases and how"},{"content":"\nWhen I first started writing about the things I was doing while learning how to code, I honestly don’t think I had any particular future plans in mind. I’d read various sources on the web and saw that it could be beneficial in finding a job, and even though I didn’t necessarily believe it would make a huge difference, I did it anyway. Over the first few months I wrote 9 articles covering the things that stuck out the most for me at the time.\nI started to notice, however, that the last few were focusing less on the lessons I was learning in actual technical topics and more on managing myself and my well-being in regard to work-life balance. I feared that if I continued in this trend then I’d more likely hinder my job hunting as I may give the impression that I’m selfish or worse, lazy. Once this idea had crept in, I more or less stopped writing and just focused on learning and gaining experience.\nThe thing with being focused solely on building yourself up is that it is incremental. So much so that it often feels as though you’re making no progress at all, and that was definitely where I was at around the end of last year. After taking a bit of a break around the new year, I came back and decided I would try to push myself in some different directions to try and shake the feeling I was reluctantly harboring. I decided I would focus a little more effort into networking, try out creating video content on YouTube, and centralize it all around making and deploying a personal website (\u0026hellip;this).\nAfter kicking around a few different ideas, one thing lead to another and I ended up with a site to show off past projects and some space for a blog. The problem was I’d stopped writing material that could go on the blog but needed something to fill the pages. So I went to my old articles that I’d posted on LinkedIn. I spent half an hour copying and pasting them into the needed markdown files which meant I was giving each a quick skim read. Something caught my attention though. I wasn’t even half the developer I am today when I wrote these less than one year ago!\nI read them all properly, in order and sat for a moment and realised… wow, I’ve actually come a very long way in a short period of time. The things that used to have me stumped for days and weeks I could now achieve in an afternoon. The level I\u0026rsquo;m actually at now, seemed unattainable back then and that gives me a great deal of hope going forward as I know that there are dizzying heights to reach and overcome, but if I got this far, then I can certainly continue!\nBesides this morale boost, I also felt like I gained a bit of clarity in the direction in which I would like to take future material. Admittedly, this realisation came a day after I started to draft this article. Writing just half of it and having read my more recent previous articles must have kicked my brain back into gear regarding searching for topics to cover, and I think I may settle on the topic that had actually caused me to stick to writing only code. I will read about, think about and write about maintaining a healthy mind and body while working in the industry I have found myself in. I already have the interest in it and a fair bit of experience, so it really makes the most sense.\nOf course I will still do a few more technical articles here and there, depending on what I do for work and in my side projects. However, I feel like the internet is absolutely saturated with far more accomplished developers than I that are making content probably much better than I would, so, I will make this promise to you and to myself right now that I\u0026rsquo;ll continue in this direction for the forseeable future, as it is probably where I can provide the most value. I may even have been leaning towards this decision before I even knew it as I think back on the description tagline I wrote for the new YouTube channel that I recently started to try and acheive one of the goals I have set myself. Even the content I will make for that may soon follow in the same path.\nI will make an effort to become known for bringing the human side of learning tech to the forefront. The highs and lows, the stressors and decompressors, the moments of being faced up to a brick wall like when I convinced myself to stop writing and the moments of elation upon breaking through it to see a wide open space before you like me right now realising what I am going to do.\nI appreciate the things I wrote before. I appreciate that I wrote them without even knowing the compounding value they would pay me back just a year later. If you are just starting out in learning web development, or any tech for that matter, there\u0026rsquo;s no reason you too shouldn\u0026rsquo;t start writing like all the advice says to. It really is a good idea. Get writing!\n","date":"2023-02-02","id":"9833861136db5e13e9dcacbf72d2b968","permalink":"https://www.mizouzie.dev/articles/re-reading-old-blogs/","summary":"Having finally made a site to house my own work, using old material from a year ago had some unexpected benefits.","tags":["self-care","mental health","learning"],"title":"Re-reading my old blogs"},{"content":"\nI\u0026rsquo;ve hit a year now working as part of a development team with PHP and Laravel. Before I was ever involved, the project I\u0026rsquo;ve worked most on was already running and comprised of a RESTful API, a CMS and umpteen instances of frontend applications that showed all the wonderfully managed data to the end users.\nEven though I\u0026rsquo;ve probably spent a few hours a day working here and there with the various code bases, I\u0026rsquo;ve only very recently felt like I know the ins and outs of how it works and that is thanks to having been given the task of writing the documentation for the whole thing. The project existed and was managed by a very small group of people, so up until now, there was no real need for docs as the group were the ones requesting features as and when they needed. However, there will soon be a new team introduced to the system and it became apparent that the application was far more complex than first envisaged.\nSo, being the junior in the company, the template was chosen and the repo was handed over to me to fill in. At first I thought it\u0026rsquo;d be a nice easy task as most of the application was fairly self explanatory. I was mistaken. There were corners of this thing I didn\u0026rsquo;t have the first clue about\u0026hellip; so how was I gonna write about how it is meant to be used?! I had to ask or just figure it out.\nA week had gone by and I\u0026rsquo;d only managed to map everything out by headings plus some lorem ipsum filler and it was amounting to around about 40 pages\u0026hellip; I couldn\u0026rsquo;t believe it was possible to have worked so many hours on something and still have such a shallow understanding of it. I needed to get writing. So I started out with what I already understood.\nOnce I\u0026rsquo;d exhausted my comfort zones I had to research. I clicked through every single possible link and button and tried every preference and setting. I spent almost another week exploring this tool I\u0026rsquo;d been staring at the bones of for the past year. And I\u0026rsquo;ll tell you what, I was kinda proud of how good the tool was! It was powerful, fast and more sensibly laid out than most web apps I\u0026rsquo;ve had to use in the past. I was amazed I\u0026rsquo;d had no idea how good the thing I\u0026rsquo;d contributed to turned out so good.\nThe shocks did not stop there though.\nI completed the task, as far as writing and first draft and formatting goes, a week ago and have had a few days on other projects and traveling since. This morning I was told to investigate and fix a bug that, a few weeks ago, would have had me scratching my head for a good few days. No head scratching today though. Before I new it, I\u0026rsquo;d checked out the reported bug, checked the raw API response that lead to it, browsed through the routes for the API and identified the controller and method for that particular endpoint and was running through the query builder string in my head to see just why the problem was occurring.\nI saw no obvious problem\u0026hellip; But before that had a chance to stump me, one particular chapter which I\u0026rsquo;d had to thoroughly investigate popped into my head and I went straight to that part of the CMS to see if what I predicted was present. IT WAS!\nJust from the new found deep understanding after writing the documentation, I was able to imagine exactly what might be causing the issue. It was a first for me with this project. My debugging had never flowed so smooth. I took this understanding, went back to the controller and added in what was missing to prevent the bug from existing. Done.\nIt took me just over 50 minutes total. Never dealt with anything on this project in such a short timeframe.\nBefore, I was just trying to -r-x (read the code and execute a task) and it was a painful and frustrating learning curve.\nNow that I am -rwx (read the code, write about the code and then execute a task) I feel like I am a level or three higher in my developer-acumen. It feels good.\nOne more reason that writing the docs is incredibly important. It isn\u0026rsquo;t just the app users that will benefit. The junior devs do too!\n","date":"2022-08-09","id":"c4130d7518f943246c78e30904702531","permalink":"https://www.mizouzie.dev/articles/rwx/","summary":"I wrote a big piece of documentation recently. Here\u0026rsquo;s how it drastically improved my developer flow.","tags":["web dev","documentation","learning"],"title":"-r(ead)w(rite)x(ecute): Documentation"},{"content":"\nLeave It For Tomorrow Seemingly controversial advice to give, but hear me out.\nWhen coding, at least learning to code, you will not only find yourself facing brand new subject matter constantly, but often trying to implement that new thing at the same time. The code you write is always to solve a problem and there are always a multitude of ways to solve it. You\u0026rsquo;ll have to choose which path you take according to other dependencies and the structure you\u0026rsquo;re using. You\u0026rsquo;ll need to think the desired process through and break it down into small enough steps before writing a single line. Sometimes you will require the help of an extra plugin or library and therefore you will need to understand how that works in itself so that you can use it effectively. Already we\u0026rsquo;ve faced more decisions than we can shake a stick at and we don\u0026rsquo;t even have anything written to show for it.\nSo you start to write. Already slightly strained in the mental sense, you hit a snag. The code doesn\u0026rsquo;t seem to work the way you predicted. Frustration sets in a bit faster than usual and you go on a tangent to try and solve this unpredictable obstacle. 15 minutes you didn\u0026rsquo;t have pass and you\u0026rsquo;re back on track. Another snag\u0026hellip;\nRinse and repeat.\nThis is the nature of web development.\nCollins dictionary defines development as: Number 3 is my favourite. Making a basic design gradually better. And it is just that when you\u0026rsquo;re starting out, gradual. This is why I say that it is not actually a bad thing to leave it for tomorrow. The process described above is mentally exhausting. The normal urge is to stick at it until the problem is resolved, but the problem is often rather more difficult to resolve than predicted. Do what you can, do not exhaust yourself, come back to it tomorrow.\nThere is a strange thing that happens when you exercise this approach. When you look upon the same project that stumped you the day before with fresh eyes, it somehow becomes much more simple and easy to overcome. Your subconscious has worked on it overnight and you are now a much more experience developer because of that and therefore much better equipped to resolve the present issue.\nOver time, the necessity to do this will be reduced as you compound your experience but there will be new challenges to face as you expand your abilities and if you managed to get into good working habits and recognise when to say \u0026ldquo;enough\u0026rdquo; and take a step back, your personal development will soar.\nSo as un-philosophical as it may sound and as irresponsible as it may feel, leaving it for tomorrow can actually be the best thing for you. If you haven\u0026rsquo;t already, I suggest you at least give it a try and see for yourself.\n","date":"2022-05-31","id":"cd0750bc0aadeea493dfab5a31f57cce","permalink":"https://www.mizouzie.dev/articles/l-i-f-t/","summary":"It\u0026rsquo;s not bad advice when I say Leave It For Tomorrow!","tags":["web dev","self-care","mental health"],"title":"L.I.F.T - the anti-advice that could save you"},{"content":"\nIn Greek mythology, Sisyphus or Sisyphos (/ˈsɪsɪfəs/; Ancient Greek: Σίσυφος Sísyphos) was the founder and king of Ephyra (now known as Corinth). Zeus punished him for cheating death twice by being forced to roll an immense boulder up a hill only for it to roll down every time it neared the top, repeating this action for eternity. Through the classical influence on modern culture, tasks that are both laborious and futile are therefore described as Sisyphean (/sɪsɪˈfiːən/). [credit Wikipedia]\nThere are a lot of times I have heard of people in web and software development feeling that their efforts reflected those of the above described mythological king. Even though I have only been in the industry a short while I myself have even seen glimmers of it in my own undertakings. The subject is one made up of a huge number of languages, libraries, frameworks and patterns. Surely impossible to know completely. But here is why that shouldn\u0026rsquo;t get you down.\nImagine you are Sisyphus. You struggle with all your might to get that stone up the hill, and it does get up the hill. That is progress, regardless of being faced with the stone back at the bottom of the hill at the start of each day. The previous day was not a waste because you proved that the stone can, in fact, be moved. The trick is to recognise both the futility along with the laborious nature of the task. Recognise and accept them both. Consider the stance of the famous French philosopher Albert Camus. Known for being a great influence on existentialism, which is define as \u0026ldquo;a philosophical theory or approach which emphasizes the existence of the individual person as a free and responsible agent determining their own development through acts of the will.\u0026rdquo; It is actually a character from one of his most famous writings The Stranger named Meursault that I want to remind you of. He is the reason that this book became my all time favourite book and the thing that I learnt from him, and in turn hope to pass on to you, is that life really \u0026ldquo;is what it is\u0026rdquo;, nothing more and nothing less. This is what I think you need to remind yourself of when facing a seemingly impossible task. It might be impossible to complete to perfection, but so what? You can still do it, and when you do, you\u0026rsquo;re very likely to get something out of it. But you mustn\u0026rsquo;t forget that it is, to a degree, ultimately futile and ensure that you stop when you\u0026rsquo;ve done enough. Thanks to it all being a little pointless, you are totally in control of when is enough.\nWhen you take this level of control over your actions, it becomes part of the reward of those actions. Choose to struggle, because it is one of the greatest teachers, but take your lesson and go. You are not futile because the task is, you are making yourself better, stronger and smarter by going through the exercise.\nAs I\u0026rsquo;m writing this my internet connection is becoming increasingly unreliable and I\u0026rsquo;m likely to loose most of what I\u0026rsquo;ve written. I will continue writing because it will ultimately help me to become a better writer. Maybe teach me the lesson to plan better, make notes first or a draft. Maybe be more prepared and plug an ethernet cable in and don\u0026rsquo;t trust the awful router we have in the house. See? lessons in struggle.\nIn closing, my main points are;\nThis industry is hard, but learn as much as you can anyway Be sure to control when you stop between efforts There are plenty of lessons to be learnt in \u0026ldquo;failures\u0026rdquo; It\u0026rsquo;s widely laughed at, the cyclic nature of the technology we\u0026rsquo;re all here trying to build. I\u0026rsquo;ll leave you with a great (and fitting) cartoon/chart I came across while putting stuff together for this. ","date":"2022-05-18","id":"8c270d60570fd9365b3d8d3efd892811","permalink":"https://www.mizouzie.dev/articles/recognise-struggle/","summary":"It is what it is. Learn what you can.","tags":["web dev","self-care","mental health"],"title":"Recognise struggle for what it is"},{"content":"\nI have learnt a lot in the last few weeks and it was thanks to taking on a personal project that was a vastly scaled down version of what I have been working with this past year. What I have learnt was not necessarily fresh knowledge, but more an understanding that had previously evaded me. The reason I hadn\u0026rsquo;t understood a lot of the concepts I was facing was because I had not built the original codebase to the original specs, I was just introduced to it in small sections and asked to work on individual features.\nThe \u0026ldquo;it\u0026rdquo; in question is an API that serves various instances of a different company blog websites. The frontend app can be included in the \u0026ldquo;it\u0026rdquo;, but I worked predominantly on the backend. This backend is built on a Laravel framework and uses Twill that was developed by the Area17 team. Both the framework and the add-on package are designed to make development quick and painless, which they do mostly, but can cause some upsets when out-of-the-ordinary requests start to come in from the clients. Stretching the capabilities of these things by having to hack the code that relies quite a lot on magic methods etc can be a cumbersome task.\nA lot of the time that I was asked to customise something I was left scratching my head at the bugs I\u0026rsquo;d introduce and have to dive deeper than my limited understanding. It stretched me and taught me a lot, but not everything.\nSo I decided to make a little version for myself. A simple blog. API with a MySQL database backend, Nuxt.js frontend. Yes, I could have used one of the thousands of pre-existing \u0026ldquo;build-a-blog\u0026rdquo; tools out there, but I wouldn\u0026rsquo;t be a true backend developer if I didn\u0026rsquo;t take the complicated route 😬.\nStarting out with the simple backend went great. I already had a repo that was the start of something with a decent set of models, routes and factories. I set up on a free hosting service that I could implement a (limited) MySQL database on, got familiar with the CLI for deployment and got on with it. Used the factories to populate the database and test my endpoints. All great.\nFrontend was more unexplored territory for me. I\u0026rsquo;d dabbled in popular frameworks before and was comfortable with bog-standard HTML and CSS with a dash of JavaScript, but I\u0026rsquo;d never started a Nuxt app from scratch. So I did. The mistake I made was that I was referring frequently to a tutorial that was for v3, while building on the stable v2\u0026hellip; I wasted about half a day before I realised so that in itself was a valuable lesson in what to pay attention to! After figuring that out and delving into the differences between the versions I had something acceptable looking in a short time and even had it pulling data from the already live RESTful API in an even shorter space of time.\nI learnt a lot about making requests, CORS and props much better than when I\u0026rsquo;d previously \u0026ldquo;studied\u0026rdquo; them on various courses I had done. It also made me consider things about the overall structure of the API I had been working with before that had never occurred to me. This is what I meant when I said I wasn\u0026rsquo;t learning new knowledge but establishing an actual understanding of what I had previously experienced. A lot of small \u0026ldquo;aaaaah ok, ok\u0026rdquo; moments.\nThe real mother-load of experience came from retro-fitting Twill into the already existing project on the backend. What I wanted it for was to allow me to add blog posts through a secure administration portal that would be totally separate from the public facing \u0026ldquo;blog page\u0026rdquo;. The thing was, as with a lot of \u0026ldquo;easy to use\u0026rdquo; packages, it would have been a lot better to use it from the very beginning and build using it\u0026rsquo;s almost auto-complete-esque CLI. It works by you telling it what modules you want and it builds your models, controllers and views for you. All you really need to do is minor customisations and tweak one or two configuration files. It really should be very easy, especially seeing as the documentation has VASTLY improved since I first tangoed with it. But because my models already existed I had to do some digging.\nThe benefit of this project is that it was a very basic version of a blog app, so it wasn\u0026rsquo;t so daunting, so I got stuck right in and learnt a tonne about the inner workings of the tool and so much clicked about stuff I\u0026rsquo;d been baffled about months beforehand in the much larger work project. It was actually enjoyable and I found that by the second day I was actually looking for small problems so that I could delve deeper in yet another direction. I ended up doing some really cool stuff I never would have had the confidence to try before.\nOverall, I am very glad that I did this and I am really looking forward to finishing it off and pushing the frontend live in the coming weeks because I really think I will feel genuinely proud of this once it\u0026rsquo;s out there. I am a much much better developer because of this project because it elevated me closer to the level of the guys who built the monster project that used to frighten me, and they are very well established dudes.\nI should also mention that I originally decided to do this when I realised that these articles that I write here on this platform (at the time: LinkedIn) are limited to be viewed only by people with a profile on here\u0026hellip; so all the one\u0026rsquo;s I\u0026rsquo;ve written previously will gradually be migrated over once the whole thing is live. I\u0026rsquo;m excited about it.\nMoral of the story:\nI was scared of the codebase I first worked on as a junior I built a diddy version of it I learnt that it really wasn\u0026rsquo;t that scary Even found a few areas that I could improve the scary codebase Now I\u0026rsquo;m a way better developer I strongly encourage developers to learn by building. If you\u0026rsquo;re like me it is incredibly valuable and makes all the hours you\u0026rsquo;ve suffered in the past totally worth it.\n","date":"2022-05-15","id":"ecc0d06ee6b27dccb60e010e31cd0e15","permalink":"https://www.mizouzie.dev/articles/build-a-little-version/","summary":"Been a while since I wrote a longer article, so here\u0026rsquo;s a longer article explaining what it is I have been doing. Basically levelling up a bit. Learning to build and building to learn!","tags":["web dev","laravel","api","learning"],"title":"If it doesn't make sense, build a little version"},{"content":"\nYou simply cannot be in web or software development and not have heard of Open Source Software. In case your computer/laptop/phone somehow has no internet connection, it\u0026rsquo;s a piece of software written by a group of developers in the public domain that can potentially accept help from anyone, anywhere. A beautifully utopian idea with roots as far back as the 60\u0026rsquo;s that has flourished over the last few decades as the world became more tech-dependant and interconnected. The most amazing thing is that our world, as it stands, relies quite heavily on technologies that came about thanks to this principle. The thing keeping the web ticking over exist thanks to Open Source Software. This link here will explain in better detail if you don\u0026rsquo;t know just how important Linux is.\nRecently it has even become a route to employment for many as it can serve as a platform to show your technical and creative abilities to people that would really appreciate them. Along with the feel good factor associated with contributing, this is likely the most obvious benefit from getting and staying involved in the movement. But since making a few contributions myself, I\u0026rsquo;d like to discuss 3 reasons you should make a start today that are maybe not so apparent. When learning web development, you quickly fall into habits. You can pick these up from those you work with, the material you are learning from or they could even spill over from completely unrelated areas of your life. The thing with habits is that they can allow you to become comfortable and if you get too comfortable then you will be getting less out of your work. Your potential to gain real value will be somewhat hindered. Should you choose to make a contribution to an Open Source project, you will be forcing yourself to adapt to a new way of doing things. For me, the most amazing thing about development is that there are so many ways to \u0026ldquo;skin a cat\u0026rdquo; as it were. In order to contribute, you need to understand what you are taking on and that involves not only reading the code, but understanding the code. The more you read, the more ways you see to achieve desired results. It will equip you with a wider coding vocabulary that can only benefit you in future endeavours. This can also greatly aid with integrating with a new team when starting a new job. Exposing yourself to a wider pool of methodologies will bolster your confidence when faced with yet another mix. Seeing a range of projects and how they are thought out and laid out will make you a better technical writer when it comes to making your own documentation. Development, and especially team development, relies a great deal on the quality of it\u0026rsquo;s internal communication. When tackling complex tasks it is vitally important that one keeps track of what steps are being taken to solve the issue at hand, and also which issues are being handled and when. Organisation is a deal breaker and trying to organise chaotic thoughts is probably a harder task than building the software. When the thoughts are recorded in a clear and concise manner, the project\u0026rsquo;s overall efficiency gets closer to 100%. A great way to become a better writer is to read more, so to become a better technical writer you need to immerse yourself in more technical writing. Seeing, following and thinking through the ideas expressed by people using the same or similar technologies to the ones your are familiar with can only give rise to your own deeper understanding of subject. You can reach one foot way out of your comfort zone while keeping the other firmly planted within it. My first experience of this is what makes me swear by Open Source as the greatest teacher of development. I am a Laravel developer and therefore I have written and ran my fair share of database migrations using PHP and the native Laravel methods. I would have said I was quite confident with them, then I came across a project that was a live accounting web application that needed some columns within its production database (price) converted from float to integer (dollars to cents). So I took it on. I wrote the migration that would alter the database columns so that future records would be made in the desired format, but what about the already existing records\u0026hellip;? This problem I had never faced. Any work I had done up until then was purely from scratch, so a change like that was no bother at all as it would not have been pushed to production yet. Honestly, I wasn\u0026rsquo;t even sure there would be a solution. So I got to asking. I consulted a colleague or two, I consulted the repository maintainers and they all pointed me in the right direction. With what I\u0026rsquo;d learnt from them, I did what all developers do and hit the search engines to find the needed documentation and boom! Within an hour I had written my first piece of SQL from within a Laravel migration file. Not only was it eye opening in the singular sense, but it was the experience that taught me that the possibilities with this kind if work are always going to be far greater than I could imagine. This has been what pushes me to learn more and more, and honestly, my interest has not waivered one iota since that day.\nI know I won\u0026rsquo;t be the greatest Open Source contributor of all time by a very very long shot, but I am absolutely and one-hundred-percently convinced that any and all contributions are the best thing anyone can do for themselves and also the collective us.\nIf you haven\u0026rsquo;t already, just go on GitHub and search for projects that might interest you and make a pull request. If that still seems daunting, even after my incredibly convincing arguments above, then go and check out my super easy to contribute to news scraping API project here, written in JavaScript and in need of all levels of contribution.\nGiving and Learning are the most rewarding things a person can do and it is what Open Source is all about. Dive in right now!\n","date":"2022-04-29","id":"6d9cf41b4eaf85f1e693a9be26f31578","permalink":"https://www.mizouzie.dev/articles/benefits-of-os/","summary":"There are so many good things about Open Source, but here are my current top 3 from the perspective of an emerging developer","tags":["web dev","open source","learning"],"title":"My Top 3 Benefits of Open Source Contribution"},{"content":"\nThe first time I attempted to deploy a Laravel project onto the popular hosting service Heroku I did not get very far. I found a number of helpful tutorials just with a few google searches, but none of them actually got me across the finish line. It was my first actual attempt at \u0026ldquo;going live\u0026rdquo; and the whole thing left me somewhat bemused and painfully aware of my lack of understanding. Both Laravel and Heroku come with ample documentation, but it may as well have been written in a foreign language as I could not make heads nor tails of it.\nToday, thankfully, was a different story.\nOnly a few weeks after my first failed attempts, I had been away and deployed a much more simple static site version of the failed project, which you can see here, using GitHub Pages. It wasn\u0026rsquo;t very difficult to transfer my blade template over to an index.html file and make the necessary changes and imports of the JavaScript files that made it all tick. That in itself was a nice learning experience, but still left my Laravel-Deployment itch very much unscratched.\nI had a recent personal project on the back burner that was in danger of fizzling out, so I figured I had nothing to lose by firing it up again, trying to remember where I left off, making it presentable to a degree and then having one more crack at Heroku because I had read in a number of places that it was very much possible to run a PHP web-app on a framework like Laravel. The difference now was that I had gone up a level or two in my search engine ability and that made all the difference. I had hit a number of stumbling blocks in my first run and they\u0026rsquo;d worn me down to the point I was unable to overcome the last few. I went right ahead and got to that same point, only this time more energized.\nI am using Laravel 9 with Tailwind CSS and deploying via the Heroku CLI.\nHere are the bits that were harder to find out about than the obvious googles:\nThe Procfile not only has to be capitalised, but MUST be present in and pushed to the heroku master branch from the local master branch. Being a fan of git and not a huge fan of Heroku, I always made heroku changes on a separate branch and pushed from there but continually saw \u0026ldquo;no Procfile found\u0026rdquo; and then that lead to the app not being run from my public/ folder on the route\u0026hellip; which was clearly specified in the Procfile.\nSet the logging to \u0026ldquo;errorlog\u0026rdquo; so that Heroku can read and display the application\u0026rsquo;s logs through both the CLI and the GUI on their handy dashboard.\nTailwind will throw a curveball if your stylesheet reference is the same as the above, and I found the reason for this in the console of the browser. When I was looking at my \u0026ldquo;deployed\u0026rdquo; site it just seemed to be a garbled mess. I was so happy to no longer be getting 500 errors or 403 errors\u0026hellip; but what I was looking at tainted my happiness. On inspection, it seemed that the CSS files were being called for, but on \u0026ldquo;http://\u0026rdquo; rather than \u0026ldquo;https://\u0026rdquo; and were therefore blocked. Heroku automatically makes your main page\u0026rsquo;s root securely accessible, but it isn\u0026rsquo;t automatic about anything else. You\u0026rsquo;ll need to set a previously non-existent variable in the .env file on the server. This can be done painlessly in two ways. Either through the CLI with the command heroku config:set ASSET_URL=\u0026lt;insert your root url here\u0026gt; or if you already have the heroku dashboard open you can view settings and click on \u0026ldquo;reveal config vars\u0026rdquo; where you have a place to add/edit as many variables as you need.\nThey were the final pieces to my puzzle that were not apparent to me the first time. I hope this list of them can save someone the pain I felt when I couldn\u0026rsquo;t get it working before. At the very least, I hope that by writing it all out and going over the process once more I, myself, might have learnt some kind of valuable lesson. Time will tell.\nIn the meantime, why don\u0026rsquo;t you check out the micro nutrient tracking site I am still developing and let me know what you think of it. (Editor note 2023-01-21: Of course Heroku is no longer free so this app is not live any more, sorry!) If anything is a particular pain point then I\u0026rsquo;d be very open to receiving issues or even pull requests on it\u0026rsquo;s github repo.\nThanks for reading, and if you got the Tekken reference at the top of this article you NEED to send me a DM or email or something, we\u0026rsquo;re basically already friends.\n","date":"2022-04-26","id":"f6df8317016161f2443ab4231bf3767f","permalink":"https://www.mizouzie.dev/articles/heroku-vs-laravel/","summary":"Deploying a Laravel app on a (then) popular free hosting platform proved tricky, so here are the steps that no-one told me.","tags":["web dev","heroku","laravel"],"title":"Heroku vs Laravel (vs me...)"},{"content":"\nGetting started in web development was one of the best decisions I ever made. It\u0026rsquo;s challenging, fulfilling and has so many avenues of opportunity. I will say, when I first started and began to recognise the scope of it I was a little taken aback. My main thoughts were:\nI\u0026rsquo;ll take forever to reach an employable level All of this is completely foreign to me This stuff is way more complicated under the nice polished UI My natural instinct to such a seemingly daunting task was to go full throttle for as long as I possibly could to get as far ahead in a short space of time. It was the way I used to work when I was solo and working for a carpet \u0026amp; upholstery cleaning company and that took 3 years to lead to burnout, but physical burnout. Surely this job is all sitting down, it can\u0026rsquo;t possibly be as bad.\nI was wrong. Very wrong.\nMental burnout is just as painful. I was pulling 10 hour shifts not moving from in front of the screen and it got to me quickly. I did learn a lot, but it took it\u0026rsquo;s toll. I had to dial it right back for a few weeks to recover because I was actually causing the physical problems I\u0026rsquo;d earnt at my old job to flair up cos I was stressing myself so much. But it was a part of my personality, I always give all I can and then keep going\u0026hellip;\nBut, I started to notice something. The code I wrote in the morning, when my head was fairly fresh was 1,000,000 times better quality than what I wrote, if I managed to write any, after 6 hours of screen time. This got me thinking. I had seen plenty on twitter about taking 5-10 minute breaks every hour and had always thought \u0026ldquo;nah, they\u0026rsquo;re just being soft\u0026rdquo;, maybe I was wrong. Too old-fashioned. Running myself into an early grave. It can\u0026rsquo;t hurt to at least try prioritising rest. Disciplined rest.\nSo I did. I forced myself to take breaks and I even made myself STOP after 5 or 6 hours every day. My overall productivity increased. My clarity of thought improved. I realised I was stressing for absolutely no reason, I couldn\u0026rsquo;t come up with a real solution to problems when my brain was tired. It was better to drop it and come back in the morning.\nI even maintained a number of personal projects which I interspersed throughout my day to give myself breaks from work. It was great and I\u0026rsquo;m in a much better position now for it because I have almost 1 year of real work experience, which would be technically true whether I worked 3 hours a day or 13 plus I have a decent little collection of solo projects where I can show off what I\u0026rsquo;ve learnt along the way. I wouldn\u0026rsquo;t be able to show the stuff I have contributed to for work because it was part of a team effort and often had a lot of guidance, it being my first year. Also it took me a few months to even be able to read and understand the code bases I worked on in full.\nThe other important thing that I learnt was that unless the bug or issue was actually critical, it really wasn\u0026rsquo;t worth losing any sleep over. A lot of the times the \u0026ldquo;fix\u0026rdquo; was simple and you actually need the break in the middle of solving it to see the best solution. Your brain would process better if given the chance to let the sub-conscience mill it over. This I only learnt from observing my experienced teammates. I thought their coolness in the face of things that initially caused me stress was due to them knowing everything already, but it really came from their experience that they would see it clearer after a break from trying to solve it. Sure they have a tonne more technical ability but they are just far more accustomed to the hang ups of problem solving, which is a very large chunk of what web \u0026amp; software development is.\nIf I\u0026rsquo;m honest, it took me a while to wrap my head around all of what was mentioned above. Actually going through the motions was a valuable experience and I\u0026rsquo;m happy with the place I\u0026rsquo;ve got to for now. There\u0026rsquo;s definitely room for improvement, but that again is further proof that this career path is about smaller incremental improvements that eventually lead to a polished, easily maintainable and future-proof final product, be it your project or yourself.\nFinally, here are some books that were recommended to me that helped me get to this point, some of which I even need to finish reading myself;\naffiliate links, I earn a bit if you buy through these Atomic Habits by James Clear REWORK by Jason Fried \u0026amp; David Heinemeier Hansson Lila by Robert M. Persig ","date":"2022-04-22","id":"766e69281441b12199c1757851248283","permalink":"https://www.mizouzie.dev/articles/know-when-to-stop/","summary":"It is vitally important to keep track of yourself when working. Let\u0026rsquo;s explore a few of the pitfalls.","tags":["web dev","self-care","mental health"],"title":"Starting is one thing, STOPPING is another"},{"content":"\nI\u0026rsquo;m familiar with Laravel and I\u0026rsquo;m fairly familiar with Livewire and AlpineJS, so by rights I should be fine building admin panels from scratch with the tools provided by this framework and packages. In theory. In reality, for me, even though I\u0026rsquo;m not a total beginner it\u0026rsquo;d take me over an hour to build it properly and then another hour to get it all working properly with model relationships, views, components and routes all doing what they\u0026rsquo;re supposed to.\nTo achieve this I\u0026rsquo;d have to keep one eye on the documentation and one eye on the IDE and be having a very good day free from distractions, which with family in the house, is a rarity. So today I was given a go on QuickAdmin which is a tool for generating the boilerplate code for Admin panels in a Laravel project that utilises Livewire and AlpineJS. It does this from whatever you input into a number of dropdown menus and modals that make up the easy-to-use GUI and all you need do is copy and paste the files into your project.\nNow, my seasoned colleague is not a fan. Mostly because they could whip the whole thing up in a short space of time using native \u0026ldquo;artisan generate\u0026rdquo; commands in the terminal. But they have 20 years in the game and I do not. This QuickAdmin tool is a leveler though! I had it all up in the browser within 20 minutes with only another 10 minutes of tweaking and customization to fit perfectly with the already existing codebase.\nThe argument against using such a tool is a fair one. You should know how to do it properly. I agree. Learning how to do it properly takes months, if not years because it isn\u0026rsquo;t a short process and the length of time it takes to complete while referring to documentation means it is hard to see the code as single coordinated unit. Using this tool solves that! I was able to get a perspective of the process I would not have seen for another 6 months and it was like a revelation. Now I feel like I\u0026rsquo;ll be able to construct an entire admin panel from the terminal in a matter of weeks rather than years.\nMoral of the story is\u0026hellip; I think beginners should be encouraged to use tools like this BECAUSE it affords them the vision they\u0026rsquo;d only acquire after a traditionally long time. I don\u0026rsquo;t think I\u0026rsquo;d use it forever, but I intend on using it for now and I\u0026rsquo;ll be a much higher level of developer a lot sooner for it.\nGo try it out here!\n","date":"2022-04-20","id":"a024173e2a6aad5b4177ac06d4639e9b","permalink":"https://www.mizouzie.dev/articles/quickadminpanel/","summary":"My first impression when using a third party tool to speed up the development process of a Laravel web app.","tags":["web dev","laravel","livewire","alpineJS"],"title":"Why I'm glad I used QuickAdminPanel today"},{"content":"\nI had spent a few days building a demonstration of what I am capable of using HTML, CSS and JavaScript. The next step was to show it off! So after hosting it using GitHub pages it was time to share it around in as many places as possible in the hope of it being noticed.\nBut there was one problem\u0026hellip; when I shared it on my LinkedIn profile, front and centre in the \u0026ldquo;Featured\u0026rdquo; section, the thumbnail was a bland and generic grey rectangle. That\u0026rsquo;s no good. How do I fix this? Is there a setting somewhere? Can I upload a decent one?\nI found the answer the way any good web developer does and hit the search engines, which actually brought me back to an article on LinkedIn, so a shout out to Nigel Cliffe and his article.\nWhat it taught me was that I needed to go back to my index.html and add a new \u0026lt;meta/\u0026gt; tag with a property of og:image. What this does is tell sites like LinkedIn and Facebook what particular images they need to render for a shared link. So I went ahead and added the image I wanted to my repository\u0026rsquo;s ./public/images folder and went to add the needed \u0026lt;meta/\u0026gt; tag to the \u0026lt;head\u0026gt;\u0026lt;head/\u0026gt; of the index.html.\nWith the meta tag you will need to set property=\u0026ldquo;og:image\u0026rdquo; and content=\u0026quot;\u0026lt;url to your image\u0026gt;\u0026quot;. Following that it is best practice to also include 2 more \u0026lt;meta/\u0026gt; tags. The first with property=\u0026ldquo;og:image:width\u0026rdquo; and content=\u0026quot;\u0026lt;the image's width in pixels\u0026gt;\u0026quot; and the second with property=\u0026ldquo;og:image:height\u0026rdquo; and content=\u0026quot;\u0026lt;the image's height in pixels\u0026gt;\u0026quot;. Theses will allow sites to render the image quickly, thus providing maximum impact when potential reads are scrolling.\nWhen these are added you can use the LinkedIn Post Inspector to see how it would look as a shared link.\nNow my feature page has a far more attractive thumbnail for the link I\u0026rsquo;m most proud of! Make sure you\u0026rsquo;re also maximizing these great free tools to show off what you can do!\n","date":"2022-04-19","id":"d261d8bbb9571bc14e7cfacdc42e25bf","permalink":"https://www.mizouzie.dev/articles/customised-featured-link-thumbnail/","summary":"How to make sure that any thumbnail of a link shared to my page looked how I wanted it to.","tags":["web dev","html","meta tag"],"title":"How I just customised my featured link thumbnail"}]